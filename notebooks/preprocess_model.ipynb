{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3944824d-c530-447e-ab28-4e6c66a7dd79",
   "metadata": {},
   "source": [
    "# Simple preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dce77626-cb95-4f3f-82f6-babe2c08c279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b72b126e-38bd-4174-ab49-7ea7e9b4d092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, cross_val_predict, learning_curve,\\\n",
    "train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import plot_confusion_matrix, classification_report, precision_recall_curve\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, SGDRegressor, SGDClassifier, Ridge, RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.compose import make_column_selector\n",
    "\n",
    "## pipeline stuff\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, make_union\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer, make_column_selector\n",
    "from sklearn import set_config; set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e04ab968-ca4c-48e1-99cb-c255bd467ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "\n",
    "class CustomOHE(TransformerMixin, BaseEstimator):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X):\n",
    "        X_dummified = X.astype(str)\n",
    "        X_dummified = X_dummified.applymap(lambda x: x if x not in [\"nan\", \"NaN\", \"NAN\", \"Nan\", \"-1\", \"-1.0\"] else float(\"nan\"))\n",
    "        X_dummified = pd.get_dummies(X_dummified)\n",
    "        self.columns = X_dummified.columns\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_dummified = X.astype(str)\n",
    "        X_dummified = X_dummified.applymap(lambda x: x if x not in [\"nan\", \"NaN\", \"NAN\", \"Nan\", \"-1\", \"-1.0\"] else float(\"nan\"))\n",
    "        X_dummified = pd.get_dummies(X_dummified)\n",
    "        # Only keep columns that are computed in the fit() method\n",
    "        # Drop new dummy columns if new category appears in the test set that were never seen in train set\n",
    "        X_dummified_reindexed = X_dummified.reindex(columns=self.columns, fill_value=0)\n",
    "        return X_dummified_reindexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca1f5989-0d50-4ac0-87b9-2cdb2c69a2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def_df = pd.read_csv(\"../raw_data/defaulter_data_13364.csv\", index_col=[0])\n",
    "pay_df = pd.read_csv(\"../raw_data/payer_data_41940.csv\", index_col=[0])\n",
    "def_df['default'] = 1\n",
    "pay_df['default'] = 0\n",
    "\n",
    "df = pd.concat([def_df, pay_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb5565e5-5b78-4ecb-b492-5899111c98f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['default']\n",
    "\n",
    "X = df.drop(columns=['default'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4abb7bf8-3052-47ad-9a09-093efa955672",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = ['B_30', \n",
    "            'B_38', \n",
    "            'D_114', \n",
    "            'D_116', \n",
    "            'D_117', \n",
    "            'D_120', \n",
    "            'D_126', \n",
    "            'D_63', \n",
    "            'D_64', \n",
    "            'D_66', \n",
    "            'D_68']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d533533d-646f-48b1-bcc8-6832b7d00285",
   "metadata": {},
   "source": [
    "drop columns if they correlate > 95% with others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd3efde1-e65c-4457-93bf-9b3d1af4b968",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_corr = X.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cc7ce56-c159-42b9-98ea-f95d49e195c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_corr = X_corr.unstack().reset_index() # Unstack correlation matrix \n",
    "X_corr.columns = ['feature_1','feature_2', 'correlation_all'] # rename columns\n",
    "X_corr.sort_values(by=\"correlation_all\",ascending=False, inplace=True) # sort by correlation\n",
    "X_corr = X_corr[X_corr['feature_1'] != X_corr['feature_2']] # Remove self correlation\n",
    "X_corr = X_corr.drop_duplicates(subset='correlation_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e97cca9-7e6f-4f4a-8953-d6d8113fddda",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_features = list(X_corr[abs(X_corr['correlation_all'])>=.95]['feature_1']) ## abs so we also consider the negative corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65f0c098-1b79-4453-bb60-08e750c652d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_red = X.drop(columns=red_features) ## dropping the highly correlated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab65db0f-0f3d-4a8a-86f0-cfa49a32c48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## checking whether the high correlations are gone\n",
    "X_red_corr = X_red.corr()\n",
    "X_red_corr = X_red_corr.unstack().reset_index() # Unstack correlation matrix \n",
    "X_red_corr.columns = ['feature_1','feature_2', 'correlation_all'] # rename columns\n",
    "X_red_corr.sort_values(by=\"correlation_all\",ascending=False, inplace=True) # sort by correlation\n",
    "X_red_corr = X_red_corr[X_red_corr['feature_1'] != X_red_corr['feature_2']] # Remove self correlation\n",
    "X_red_corr = X_red_corr.drop_duplicates(subset='correlation_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36893cdd-8644-48b8-990f-34ab4f9fc1a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>correlation_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12045</th>\n",
       "      <td>D_74</td>\n",
       "      <td>D_58</td>\n",
       "      <td>0.927332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6471</th>\n",
       "      <td>B_13</td>\n",
       "      <td>B_12</td>\n",
       "      <td>0.921825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>B_2</td>\n",
       "      <td>B_33</td>\n",
       "      <td>0.913250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>S_3</td>\n",
       "      <td>S_7</td>\n",
       "      <td>0.903899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28001</th>\n",
       "      <td>D_131</td>\n",
       "      <td>D_132</td>\n",
       "      <td>0.891850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9398</th>\n",
       "      <td>B_20</td>\n",
       "      <td>B_2</td>\n",
       "      <td>-0.779728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5981</th>\n",
       "      <td>S_8</td>\n",
       "      <td>S_15</td>\n",
       "      <td>-0.783457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23888</th>\n",
       "      <td>B_39</td>\n",
       "      <td>B_17</td>\n",
       "      <td>-0.805295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11791</th>\n",
       "      <td>D_73</td>\n",
       "      <td>D_108</td>\n",
       "      <td>-0.851429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>P_2</td>\n",
       "      <td>D_87</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14849 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature_1 feature_2  correlation_all\n",
       "12045      D_74      D_58         0.927332\n",
       "6471       B_13      B_12         0.921825\n",
       "457         B_2      B_33         0.913250\n",
       "728         S_3       S_7         0.903899\n",
       "28001     D_131     D_132         0.891850\n",
       "...         ...       ...              ...\n",
       "9398       B_20       B_2        -0.779728\n",
       "5981        S_8      S_15        -0.783457\n",
       "23888      B_39      B_17        -0.805295\n",
       "11791      D_73     D_108        -0.851429\n",
       "99          P_2      D_87              NaN\n",
       "\n",
       "[14849 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_red_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "742c0878-a19a-4bd3-ad67-f60ee5e95124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(red_features) ## we removed 13 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dab05a-f828-4547-b0ad-a975585c1be4",
   "metadata": {},
   "source": [
    "drop columns with nans if in __both__ groups > 80% nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d229f31-4e9e-4e50-9bab-7074d7cd3182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def_nans = def_df.isna().sum()/len(def_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ce797b7-2d83-4f61-af78-32b64b7c717a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def_nans_80 = def_nans[def_nans >= 0.8].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f75a67ef-b1c2-4224-a663-4273c6465fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_nans = pay_df.isna().sum()/len(pay_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e90e21f2-228f-4b14-bd89-ac3f7ab79add",
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_nans_80 = pay_nans[pay_nans>=0.8].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d308f3a7-f73a-419c-8600-6034b4f418b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nans_80 = [feature for feature in pay_nans_80 if feature in def_nans_80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc740bb6-8679-4b70-92d3-5cf851b69500",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check whether features were already removed\n",
    "red_features_nan = [feature for feature in nans_80 if feature not in red_features] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e09f028c-b5f1-4996-ba28-93ad51434137",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_red = X_red.drop(columns=red_features_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f283116b-9841-497f-b3ca-018d69e7b69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_columns = red_features + red_features_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b7dfc18-31c0-4345-8b6f-032b7ddad524",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_cat_vars = [var for var in cat_vars if var not in dropped_columns] ## categorical variables that are left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72c6ae11-a0af-41a4-af41-e82cd7a7006e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute mean/most frequent value for other nans (specific to group?)\n",
    "# robustscale all numerical values\n",
    "\n",
    "num_imputer = SimpleImputer(strategy=\"mean\") ## replace with KNNIMputer\n",
    "num_scaler = RobustScaler()\n",
    "\n",
    "\n",
    "num_pipe = make_pipeline(num_imputer, num_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68561261-6613-46d7-a1d4-1fdf441670b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make_column_selector(red_cat_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7967d18d-8d62-48f1-8097-303b4548343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_imputer = SimpleImputer(strategy=\"most_frequent\") ## replace with KNNimputer on one neighbour, after transforming to numericals\n",
    "#cat_encoder = CustomOHE() ## does not work with numpy.arrays in COlumn_transformer yet\n",
    "cat_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "cat_pipe = make_pipeline(cat_imputer, cat_encoder)\n",
    "#preprocessing_pipe = make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ebe538-159d-4837-b1b4-440958d04432",
   "metadata": {},
   "source": [
    "Beware of the Dummy trap. (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "537b58d8-b1dc-4e98-8a57-718af24b0293",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vars = [feature for feature in X_red.columns[2:] if feature not in cat_vars] ## exclude dates and IDs (first two columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04692da7-207d-43e7-9ace-c1223c031b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(num_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c7c3410-c176-4e86-9d4e-9b87a9d59bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_red.columns[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "708cba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_red.index=X_red['customer_ID']\n",
    "X_red_new=X_red.drop(columns=['customer_ID','S_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60a778d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.index=X_red['customer_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb2fa585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_red_new, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2ae4aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    ('num_pip', num_pipe, num_vars),\n",
    "    ('cat_pip', cat_pipe, red_cat_vars)],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41d67893",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data=pd.DataFrame(preprocessor.fit_transform(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8728c17a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huhuzl/.pyenv/versions/3.8.12/envs/AMEX_predict_default/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "lr=LogisticRegression()\n",
    "lr.fit(new_data,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c4d3cad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tran=preprocessor.transform(X_test)\n",
    "y_pre=lr.predict(X_test_tran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b9722c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c38bc890",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre_df=pd.DataFrame(data=y_pre,columns=['prediction'])\n",
    "\n",
    "y_test_df=y_test.to_frame()\n",
    "\n",
    "y_test_df.columns=['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5dda12a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_df.index=y_test.index\n",
    "y_pre_df.index=X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec38f196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def amex_metric(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "\n",
    "    def top_four_percent_captured(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        four_pct_cutoff = int(0.04 * df['weight'].sum())\n",
    "        df['weight_cumsum'] = df['weight'].cumsum()\n",
    "        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n",
    "    def weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n",
    "        total_pos = (df['target'] * df['weight']).sum()\n",
    "        df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n",
    "        df['lorentz'] = df['cum_pos_found'] / total_pos\n",
    "        df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n",
    "        return df['gini'].sum()\n",
    "\n",
    "    def normalized_weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        y_true_pred = y_true.rename(columns={'target': 'prediction'})\n",
    "        return weighted_gini(y_true, y_pred) / weighted_gini(y_true, y_true_pred)\n",
    "\n",
    "    g = normalized_weighted_gini(y_true, y_pred)\n",
    "    d = top_four_percent_captured(y_true, y_pred)\n",
    "\n",
    "    return 0.5 * (g + d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753362c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa32fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769971d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "all_columns=new_data.columns\n",
    "\n",
    "pca = PCA(n_components=20)\n",
    "pca.fit(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22278edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access our 13 PCs \n",
    "W = pca.components_\n",
    "\n",
    "# Print PCs as COLUMNS\n",
    "W = pd.DataFrame(W.T,\n",
    "                 index=all_columns,\n",
    "                 columns=[f'PC{i}' for i in range(1, 6)])\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8a9edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_proj = pca.transform(new_data)\n",
    "X_proj = pd.DataFrame(X_proj, columns=[f'PC{i}' for i in range(1, 6)])\n",
    "X_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46f127b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "lr=LogisticRegression()\n",
    "\n",
    "results=cross_validate(lr,new_data,y,scoring=['recall','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139fb0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cf9975",
   "metadata": {},
   "outputs": [],
   "source": [
    "amex_metric(y_test_df,y_pre_df) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
