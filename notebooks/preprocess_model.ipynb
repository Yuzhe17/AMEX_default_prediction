{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3944824d-c530-447e-ab28-4e6c66a7dd79",
   "metadata": {},
   "source": [
    "# Simple preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dce77626-cb95-4f3f-82f6-babe2c08c279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, cross_val_predict, learning_curve,\\\n",
    "train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import plot_confusion_matrix, classification_report, precision_recall_curve\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, SGDRegressor, SGDClassifier, Ridge, RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.compose import make_column_selector\n",
    "\n",
    "## pipeline stuff\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, make_union\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer, make_column_selector\n",
    "from sklearn import set_config; set_config(display='diagram')\n",
    "\n",
    "def_df = pd.read_csv(\"../raw_data/defaulter_data_13364.csv\", index_col=[0])\n",
    "pay_df = pd.read_csv(\"../raw_data/payer_data_41940.csv\", index_col=[0])\n",
    "def_df['default'] = 1\n",
    "pay_df['default'] = 0\n",
    "\n",
    "df = pd.concat([def_df, pay_df])\n",
    "\n",
    "y = df['default']\n",
    "\n",
    "X = df.drop(columns=['default'])\n",
    "\n",
    "cat_vars = ['B_30', \n",
    "            'B_38', \n",
    "            'D_114', \n",
    "            'D_116', \n",
    "            'D_117', \n",
    "            'D_120', \n",
    "            'D_126', \n",
    "            'D_63', \n",
    "            'D_64', \n",
    "            'D_66', \n",
    "            'D_68']\n",
    "\n",
    "#drop columns if they correlate > 95% with others\n",
    "\n",
    "X_corr = X.corr()\n",
    "\n",
    "X_corr = X_corr.unstack().reset_index() # Unstack correlation matrix \n",
    "X_corr.columns = ['feature_1','feature_2', 'correlation_all'] # rename columns\n",
    "X_corr.sort_values(by=\"correlation_all\",ascending=False, inplace=True) # sort by correlation\n",
    "X_corr = X_corr[X_corr['feature_1'] != X_corr['feature_2']] # Remove self correlation\n",
    "X_corr = X_corr.drop_duplicates(subset='correlation_all')\n",
    "\n",
    "red_features = list(X_corr[abs(X_corr['correlation_all'])>=.95]['feature_1']) ## abs so we also consider the negative corrs\n",
    "\n",
    "X_red = X.drop(columns=red_features) ## dropping the highly correlated columns\n",
    "\n",
    "## checking whether the high correlations are gone\n",
    "X_red_corr = X_red.corr()\n",
    "X_red_corr = X_red_corr.unstack().reset_index() # Unstack correlation matrix \n",
    "X_red_corr.columns = ['feature_1','feature_2', 'correlation_all'] # rename columns\n",
    "X_red_corr.sort_values(by=\"correlation_all\",ascending=False, inplace=True) # sort by correlation\n",
    "X_red_corr = X_red_corr[X_red_corr['feature_1'] != X_red_corr['feature_2']] # Remove self correlation\n",
    "X_red_corr = X_red_corr.drop_duplicates(subset='correlation_all')\n",
    "\n",
    "print(f'{len(red_features)} of features are removed') ## we removed 13 columns\n",
    "\n",
    "drop columns with nans if in __both__ groups > 80% nans\n",
    "\n",
    "def_nans = def_df.isna().sum()/len(def_df) \n",
    "\n",
    "def_nans_80 = def_nans[def_nans >= 0.8].index\n",
    "\n",
    "pay_nans = pay_df.isna().sum()/len(pay_df)\n",
    "\n",
    "pay_nans_80 = pay_nans[pay_nans>=0.8].index\n",
    "\n",
    "nans_80 = [feature for feature in pay_nans_80 if feature in def_nans_80]\n",
    "\n",
    "## check whether features were already removed\n",
    "red_features_nan = [feature for feature in nans_80 if feature not in red_features] \n",
    "\n",
    "X_red = X_red.drop(columns=red_features_nan)\n",
    "\n",
    "dropped_columns = red_features + red_features_nan\n",
    "\n",
    "df_dropped=df.drop(columns=dropped_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ca6428a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55304, 163)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7dfc18-31c0-4345-8b6f-032b7ddad524",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_cat_vars = [var for var in cat_vars if var not in dropped_columns] ## categorical variables that are left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c6ae11-a0af-41a4-af41-e82cd7a7006e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute mean/most frequent value for other nans (specific to group?)\n",
    "# robustscale all numerical values\n",
    "\n",
    "num_imputer = SimpleImputer(strategy=\"mean\") ## replace with KNNIMputer\n",
    "num_scaler = RobustScaler()\n",
    "\n",
    "\n",
    "num_pipe = make_pipeline(num_imputer, num_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68561261-6613-46d7-a1d4-1fdf441670b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make_column_selector(red_cat_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7967d18d-8d62-48f1-8097-303b4548343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_imputer = SimpleImputer(strategy=\"most_frequent\") ## replace with KNNimputer on one neighbour, after transforming to numericals\n",
    "#cat_encoder = CustomOHE() ## does not work with numpy.arrays in COlumn_transformer yet\n",
    "cat_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "cat_pipe = make_pipeline(cat_imputer, cat_encoder)\n",
    "#preprocessing_pipe = make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ebe538-159d-4837-b1b4-440958d04432",
   "metadata": {},
   "source": [
    "Beware of the Dummy trap. (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537b58d8-b1dc-4e98-8a57-718af24b0293",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vars = [feature for feature in X_red.columns[2:] if feature not in cat_vars] ## exclude dates and IDs (first two columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04692da7-207d-43e7-9ace-c1223c031b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(num_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7c3410-c176-4e86-9d4e-9b87a9d59bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_red.columns[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708cba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_red.index=X_red['customer_ID']\n",
    "X_red_new=X_red.drop(columns=['customer_ID','S_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a778d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.index=X_red['customer_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2fa585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_red_new, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ae4aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    ('num_pip', num_pipe, num_vars),\n",
    "    ('cat_pip', cat_pipe, red_cat_vars)],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d67893",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data=pd.DataFrame(preprocessor.fit_transform(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8728c17a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "lr=LogisticRegression()\n",
    "lr.fit(new_data,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d3cad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tran=preprocessor.transform(X_test)\n",
    "y_pre=lr.predict(X_test_tran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b9722c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38bc890",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre_df=pd.DataFrame(data=y_pre,columns=['prediction'])\n",
    "\n",
    "y_test_df=y_test.to_frame()\n",
    "\n",
    "y_test_df.columns=['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dda12a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_df.index=y_test.index\n",
    "y_pre_df.index=X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec38f196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def amex_metric(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "\n",
    "    def top_four_percent_captured(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        four_pct_cutoff = int(0.04 * df['weight'].sum())\n",
    "        df['weight_cumsum'] = df['weight'].cumsum()\n",
    "        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n",
    "    def weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n",
    "        total_pos = (df['target'] * df['weight']).sum()\n",
    "        df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n",
    "        df['lorentz'] = df['cum_pos_found'] / total_pos\n",
    "        df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n",
    "        return df['gini'].sum()\n",
    "\n",
    "    def normalized_weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        y_true_pred = y_true.rename(columns={'target': 'prediction'})\n",
    "        return weighted_gini(y_true, y_pred) / weighted_gini(y_true, y_true_pred)\n",
    "\n",
    "    g = normalized_weighted_gini(y_true, y_pred)\n",
    "    d = top_four_percent_captured(y_true, y_pred)\n",
    "\n",
    "    return 0.5 * (g + d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cf9975",
   "metadata": {},
   "outputs": [],
   "source": [
    "amex_metric(y_test_df,y_pre_df) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "8913934a659d2fd96ba33870e386b5c0df67ae5c1feb0db7372eaabfc1cf93b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
