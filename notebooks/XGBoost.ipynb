{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bc7d0b6",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f174751e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, cross_val_predict, learning_curve,\\\n",
    "train_test_split, GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, OneHotEncoder, FunctionTransformer, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import plot_confusion_matrix, classification_report, precision_recall_curve\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, SGDRegressor, SGDClassifier, Ridge, RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.compose import make_column_selector\n",
    "\n",
    "## pipeline stuff\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, make_union\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer, make_column_selector\n",
    "from sklearn import set_config; set_config(display='diagram')\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550ed72f",
   "metadata": {},
   "source": [
    "# Data unprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b8ba9c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def_df = pd.read_parquet(\"/Users/sjoerddewit/Desktop/Programming/6 Le Wagon Data Science/final_project/defaulter_data_20k_ids_compress.parquet\")\n",
    "pay_df = pd.read_parquet(\"/Users/sjoerddewit/Desktop/Programming/6 Le Wagon Data Science/final_project/payer_data_20k_ids.parquet\")\n",
    "\n",
    "def_df['default'] = 1\n",
    "pay_df['default'] = 0\n",
    "\n",
    "df = pd.concat([def_df, pay_df])\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "train_y = df['default'].reset_index(drop=True)\n",
    "\n",
    "train_x = df.drop(columns=['default']).reset_index(drop=True)\n",
    "train_x.drop(columns=['customer_ID',\n",
    "                     'S_2'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0b1a97",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c6dbe622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116027, 190) (243953, 190)\n",
      "done ✅\n"
     ]
    }
   ],
   "source": [
    "# def_df = pd.read_csv(\"/home/slawa/code/code-rep0/projects/data/defaulter_data_13364.csv\", index_col=[0])\n",
    "# pay_df = pd.read_csv(\"/home/slawa/code/code-rep0/projects/data/payer_data_41940.csv\", index_col=[0])\n",
    "\n",
    "# def_df = pd.read_parquet(\"/Users/sjoerddewit/Desktop/Programming/6 Le Wagon Data Science/final_project/defaulter_data_6k_ids_compress.parquet\")\n",
    "def_df = pd.read_parquet(\"/Users/sjoerddewit/Desktop/Programming/6 Le Wagon Data Science/final_project/defaulter_data_20k_ids_compress.parquet\")\n",
    "pay_df = pd.read_parquet(\"/Users/sjoerddewit/Desktop/Programming/6 Le Wagon Data Science/final_project/payer_data_20k_ids.parquet\")\n",
    "\n",
    "def_df['default'] = 1\n",
    "pay_df['default'] = 0\n",
    "\n",
    "df = pd.concat([def_df, pay_df])\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "y = df['default'].reset_index(drop=True)\n",
    "\n",
    "X = df.drop(columns=['default']).reset_index(drop=True)\n",
    "\n",
    "cat_vars = ['B_30', \n",
    "            'B_38', \n",
    "            'D_114', \n",
    "            'D_116', \n",
    "            'D_117', \n",
    "            'D_120', \n",
    "            'D_126', \n",
    "            'D_63', \n",
    "            'D_64', \n",
    "            'D_66', \n",
    "            'D_68']\n",
    "\n",
    "X_corr = X.corr()\n",
    "\n",
    "X_corr = X_corr.unstack().reset_index() # Unstack correlation matrix \n",
    "X_corr.columns = ['feature_1','feature_2', 'correlation_all'] # rename columns\n",
    "X_corr.sort_values(by=\"correlation_all\",ascending=False, inplace=True) # sort by correlation\n",
    "X_corr = X_corr[X_corr['feature_1'] != X_corr['feature_2']] # Remove self correlation\n",
    "X_corr = X_corr.drop_duplicates(subset='correlation_all')\n",
    "\n",
    "red_features = list(X_corr[abs(X_corr['correlation_all'])>=.95]['feature_1']) ## abs so we also consider the negative corrs\n",
    "\n",
    "X_red = X.drop(columns=red_features) ## dropping the highly correlated columns\n",
    "\n",
    "## checking whether the high correlations are gone\n",
    "X_red_corr = X_red.corr()\n",
    "X_red_corr = X_red_corr.unstack().reset_index() # Unstack correlation matrix \n",
    "X_red_corr.columns = ['feature_1','feature_2', 'correlation_all'] # rename columns\n",
    "X_red_corr.sort_values(by=\"correlation_all\",ascending=False, inplace=True) # sort by correlation\n",
    "X_red_corr = X_red_corr[X_red_corr['feature_1'] != X_red_corr['feature_2']] # Remove self correlation\n",
    "X_red_corr = X_red_corr.drop_duplicates(subset='correlation_all')\n",
    "\n",
    "\n",
    "## drop columns with nans if in both groups > 80% nans\n",
    "\n",
    "nan_threshold= 0.8 ## adjust the hardcoded values\n",
    "def_nans = def_df.isna().sum()/len(def_df) \n",
    "def_nans_80 = def_nans[def_nans >= nan_threshold].index\n",
    "pay_nans = pay_df.isna().sum()/len(pay_df)\n",
    "pay_nans_80 = pay_nans[pay_nans>= nan_threshold].index\n",
    "nans_80 = [feature for feature in pay_nans_80 if feature in def_nans_80]\n",
    "\n",
    "## check whether features were already removed\n",
    "red_features_nan = [feature for feature in nans_80 if feature not in red_features] \n",
    "X_red = X_red.drop(columns=red_features_nan)\n",
    "dropped_columns = red_features + red_features_nan\n",
    "\n",
    "## Builsing the pipeline\n",
    "num_vars = [feature for feature in X_red.columns[2:] if feature not in cat_vars] ## exclude dates and IDs (first two columns)\n",
    "str_vars = [feature for feature in X_red.columns[2:] if not pd.api.types.is_numeric_dtype(X_red[feature])] ## columns that are not numeric at all \n",
    "#red_cat_vars = [feature for feature in cat_vars if feature not in dropped_columns + str_vars] ## remaining categorical variables that have no string values\n",
    "red_cat_vars = [feature for feature in cat_vars if feature not in dropped_columns + str_vars] ## remaining categorical variables \n",
    "\n",
    "\n",
    "# impute mean/most frequent value for other nans (specific to group?)\n",
    "# robustscale all numerical values\n",
    "\n",
    "num_imputer = SimpleImputer(strategy='mean')\n",
    "num_scaler = RobustScaler()\n",
    "\n",
    "#num_imputer = KNNImputer(n_neighbors=2) ## KNNIMputer is computationally demanding\n",
    "## should come AFTER SCALING\n",
    "\n",
    "num_pipe = make_pipeline(num_imputer, num_scaler)\n",
    "\n",
    "#str_trans = OrdinalEncoder() # is only needed if one wants to do knnimputer\n",
    "\n",
    "#nan_trans = FunctionTransformer(nan_imp)\n",
    "\n",
    "#nan_trans = FunctionTransformer(lambda X: X.applymap(lambda x: np.nan if x in [-1,-1.0, \"-1.0\", \"-1\"] else x))\n",
    "\n",
    "cat_imputer = SimpleImputer(strategy=\"most_frequent\") ## replace with KNNimputer on one neighbour, after transforming to numericals\n",
    "#cat_imputer = KNNImputer(n_neighbors=1) # introducing it did not improve performance, but is computationally demanding\n",
    "cat_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore') ## what happens to the old columns?\n",
    "cat_pipe = make_pipeline(cat_imputer, cat_encoder)\n",
    "#str_pipe = make_pipeline(cat_imputer, str_trans, cat_encoder)\n",
    "#str_pipe = make_pipeline(cat_imputer, cat_encoder)\n",
    "# impute mean/most frequent value for other nans (specific to group?)\n",
    "# robustscale all numerical values\n",
    "\n",
    "num_imputer = SimpleImputer(strategy='mean')\n",
    "num_scaler = RobustScaler()\n",
    "\n",
    "#num_imputer = KNNImputer(n_neighbors=2) ## KNNIMputer is computationally demanding\n",
    "## should come AFTER SCALING\n",
    "\n",
    "num_pipe = make_pipeline(num_imputer, num_scaler)\n",
    "\n",
    "#str_trans = OrdinalEncoder() # is only needed if one wants to do knnimputer\n",
    "\n",
    "#nan_trans = FunctionTransformer(nan_imp)\n",
    "\n",
    "#nan_trans = FunctionTransformer(lambda X: X.applymap(lambda x: np.nan if x in [-1,-1.0, \"-1.0\", \"-1\"] else x))\n",
    "\n",
    "cat_imputer = SimpleImputer(strategy=\"most_frequent\") ## replace with KNNimputer on one neighbour, after transforming to numericals\n",
    "#cat_imputer = KNNImputer(n_neighbors=1) # introducing it did not improve performance, but is computationally demanding\n",
    "cat_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore') ## what happens to the old columns?\n",
    "cat_pipe = make_pipeline(cat_imputer, cat_encoder)\n",
    "#str_pipe = make_pipeline(cat_imputer, str_trans, cat_encoder)\n",
    "#str_pipe = make_pipeline(cat_imputer, cat_encoder)\n",
    "\n",
    "print('done ✅')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eced2722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6k defaulters = (76747, 190) 20k payer = (243953, 190)  \n",
    "# 20k defaulters = (116027, 190) 20k payer = (243953, 190)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c944d6b",
   "metadata": {},
   "source": [
    "# A self-contained alternative Nans imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "333eeb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done ✅\n"
     ]
    }
   ],
   "source": [
    "def alt_nan_imp(X):\n",
    "    \n",
    "    cat_vars = ['B_30', \n",
    "            'B_38', \n",
    "            'D_114', \n",
    "            'D_116', \n",
    "            'D_117', \n",
    "            'D_120', \n",
    "            'D_126', \n",
    "            'D_63', \n",
    "            'D_64', \n",
    "            'D_66', \n",
    "            'D_68']\n",
    "    \n",
    "    alt_nan_list = [-1,-1.0, \"-1.0\", \"-1\"]\n",
    "    \n",
    "    cat_columns = [column for column in X.columns if column in cat_vars]\n",
    "    \n",
    "    X[cat_columns] = X[cat_columns].applymap(lambda x: np.nan if x in alt_nan_list else x)\n",
    "\n",
    "alt_nan_imp(X_red)\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num_pip', num_pipe, num_vars),\n",
    "    ('cat_pip', cat_pipe, red_cat_vars)],\n",
    "    remainder='drop' ## all columns not in num_vars and red_cat_vars are dropped.\n",
    ")\n",
    "\n",
    "alt_nan_imp(X)\n",
    "preprocessor.fit(X)\n",
    "\n",
    "X_pp = pd.DataFrame(preprocessor.fit_transform(X_red))\n",
    "X_pp['customer_ID'] = X_red['customer_ID']\n",
    "X_pp_avg = X_pp.groupby('customer_ID').mean()\n",
    "y_ID = pd.DataFrame(y)\n",
    "y_ID['customer_ID'] = X_red['customer_ID']\n",
    "y_unique = y_ID.groupby('customer_ID').mean().astype(int) ## actually, this data is just in train_labels\n",
    "X_pp_avg_train, X_pp_avg_val, y_unique_train, y_unique_val = train_test_split(X_pp_avg, y_unique, test_size=0.3) \n",
    "\n",
    "\n",
    "if 'customer_ID' in X_pp.columns:\n",
    "    X_pp.drop(columns='customer_ID', inplace=True)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "# # Train_test_split needs to be on preprocessed data\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "\n",
    "# pp_pred_pipe = make_pipeline(preprocessor, mod)\n",
    "# pp_pred_pipe\n",
    "# pp_pred_pipe.fit(X, y)\n",
    "\n",
    "print('done ✅')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc89b422",
   "metadata": {},
   "source": [
    "# Creating custom amex scoring metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "58715c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done ✅\n"
     ]
    }
   ],
   "source": [
    "def amex_metric(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "    \n",
    "    ## TWEAK\n",
    "    y_true = pd.DataFrame(y_true.reset_index(drop=True))\n",
    "    y_pred = pd.DataFrame(y_pred)\n",
    "    \n",
    "    y_true = y_true.rename(columns={y_true.columns[0]:'target'})\n",
    "    y_pred = y_pred.rename(columns={y_pred.columns[0]:'prediction'})\n",
    "    ##\n",
    "    \n",
    "    def top_four_percent_captured(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        four_pct_cutoff = int(0.04 * df['weight'].sum())\n",
    "        df['weight_cumsum'] = df['weight'].cumsum()\n",
    "        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n",
    "    def weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n",
    "        total_pos = (df['target'] * df['weight']).sum()\n",
    "        df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n",
    "        df['lorentz'] = df['cum_pos_found'] / total_pos\n",
    "        df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n",
    "        return df['gini'].sum()\n",
    "\n",
    "    def normalized_weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        y_true_pred = y_true.rename(columns={'target': 'prediction'})\n",
    "        return weighted_gini(y_true, y_pred) / weighted_gini(y_true, y_true_pred)\n",
    "\n",
    "    g = normalized_weighted_gini(y_true, y_pred)\n",
    "    d = top_four_percent_captured(y_true, y_pred)\n",
    "\n",
    "    return 0.5 * (g + d)\n",
    "\n",
    "print('done ✅')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7998583a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done ✅\n"
     ]
    }
   ],
   "source": [
    "amex_metric_scorer = make_scorer(amex_metric)\n",
    "\n",
    "## dict of scoring metrics one might want to pass into cross validation\n",
    "scorings = {'recall':'recall',\n",
    "            'f1':'f1',\n",
    "           'amex': amex_metric_scorer}\n",
    "\n",
    "print('done ✅')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1d3e69",
   "metadata": {},
   "source": [
    "# Averaging preprocessed X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2caf0d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done ✅\n",
      "(30000, 183) (30000, 1)\n"
     ]
    }
   ],
   "source": [
    "X_pp['customer_ID'] = X_red['customer_ID']\n",
    "# X_avg_pp = X_pp.groupby('customer_ID').mean()\n",
    "X_avg_pp = X_pp.groupby('customer_ID').agg(['mean', \n",
    "#                                             'last', \n",
    "#                                             'first',\n",
    "#                                            'max',\n",
    "#                                            'min'\n",
    "                                           ])\n",
    "\n",
    "\n",
    "y_ID = pd.DataFrame(y)\n",
    "y_ID['customer_ID'] = X_red['customer_ID']\n",
    "## actually, this data is just in train_labels\n",
    "y_unique = y_ID.groupby('customer_ID').mean().astype(int)\n",
    "# y_unique = y_ID.groupby('customer_ID').agg(['mean', 'last', 'first']).astype(int)\n",
    "\n",
    "\n",
    "print('done ✅')\n",
    "\n",
    "print(X_avg_pp.shape , y_unique.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3132c42f",
   "metadata": {},
   "source": [
    "# XG Boost & Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "411bb311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Version 2.0.0-dev\n",
      "done ✅\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold \n",
    "import xgboost as xgb\n",
    "print('XGB Version',xgb.__version__)\n",
    "\n",
    "print('done ✅')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a261b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# xgb_class = XGBClassifier()\n",
    "\n",
    "# # Hyperparameter Grid\n",
    "# grid = {'max_depth': [3, 5, 7], \n",
    "#         'n_estimators': [88, 90, 92],\n",
    "#         'learning_rate': [0.09, 0.1, 0.11]\n",
    "#          }\n",
    "\n",
    "# # Instanciate Grid Search\n",
    "# search = GridSearchCV(xgb_class, \n",
    "#                       grid, \n",
    "# #                       scoring = 'r2',\n",
    "#                       cv = 5,\n",
    "#                       n_jobs=-1 # paralellize computation\n",
    "#                      ) \n",
    "\n",
    "\n",
    "# search.fit(X_pp_avg_train, y_unique_train,\n",
    "#     # evaluate loss at each iteration\n",
    "#     eval_set=[(X_pp_avg_train,y_unique_train), (X_pp_avg_val, y_unique_val)],  \n",
    "#     # stop iterating when eval loss increases 5 times in a row\n",
    "#     early_stopping_rounds=2\n",
    "# )\n",
    "\n",
    "# print('done ✅')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a158289",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536c893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f22254",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003f4abe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "54cd2566",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.61484\tvalidation_1-logloss:0.63506\n",
      "[1]\tvalidation_0-logloss:0.55037\tvalidation_1-logloss:0.58799\n",
      "[2]\tvalidation_0-logloss:0.49521\tvalidation_1-logloss:0.54857\n",
      "[3]\tvalidation_0-logloss:0.44730\tvalidation_1-logloss:0.51570\n",
      "[4]\tvalidation_0-logloss:0.40567\tvalidation_1-logloss:0.48718\n",
      "[5]\tvalidation_0-logloss:0.36897\tvalidation_1-logloss:0.46266\n",
      "[6]\tvalidation_0-logloss:0.33652\tvalidation_1-logloss:0.44163\n",
      "[7]\tvalidation_0-logloss:0.30766\tvalidation_1-logloss:0.42338\n",
      "[8]\tvalidation_0-logloss:0.28197\tvalidation_1-logloss:0.40780\n",
      "[9]\tvalidation_0-logloss:0.25928\tvalidation_1-logloss:0.39392\n",
      "[10]\tvalidation_0-logloss:0.23863\tvalidation_1-logloss:0.38159\n",
      "[11]\tvalidation_0-logloss:0.22027\tvalidation_1-logloss:0.37053\n",
      "[12]\tvalidation_0-logloss:0.20367\tvalidation_1-logloss:0.36097\n",
      "[13]\tvalidation_0-logloss:0.18865\tvalidation_1-logloss:0.35270\n",
      "[14]\tvalidation_0-logloss:0.17511\tvalidation_1-logloss:0.34508\n",
      "[15]\tvalidation_0-logloss:0.16271\tvalidation_1-logloss:0.33840\n",
      "[16]\tvalidation_0-logloss:0.15153\tvalidation_1-logloss:0.33309\n",
      "[17]\tvalidation_0-logloss:0.14135\tvalidation_1-logloss:0.32719\n",
      "[18]\tvalidation_0-logloss:0.13209\tvalidation_1-logloss:0.32214\n",
      "[19]\tvalidation_0-logloss:0.12354\tvalidation_1-logloss:0.31775\n",
      "[20]\tvalidation_0-logloss:0.11567\tvalidation_1-logloss:0.31398\n",
      "[21]\tvalidation_0-logloss:0.10859\tvalidation_1-logloss:0.31094\n",
      "[22]\tvalidation_0-logloss:0.10205\tvalidation_1-logloss:0.30826\n",
      "[23]\tvalidation_0-logloss:0.09604\tvalidation_1-logloss:0.30587\n",
      "[24]\tvalidation_0-logloss:0.09052\tvalidation_1-logloss:0.30389\n",
      "[25]\tvalidation_0-logloss:0.08535\tvalidation_1-logloss:0.30207\n",
      "[26]\tvalidation_0-logloss:0.08068\tvalidation_1-logloss:0.30039\n",
      "[27]\tvalidation_0-logloss:0.07633\tvalidation_1-logloss:0.29896\n",
      "[28]\tvalidation_0-logloss:0.07227\tvalidation_1-logloss:0.29773\n",
      "[29]\tvalidation_0-logloss:0.06854\tvalidation_1-logloss:0.29671\n",
      "[30]\tvalidation_0-logloss:0.06509\tvalidation_1-logloss:0.29621\n",
      "[31]\tvalidation_0-logloss:0.06190\tvalidation_1-logloss:0.29556\n",
      "[32]\tvalidation_0-logloss:0.05896\tvalidation_1-logloss:0.29476\n",
      "[33]\tvalidation_0-logloss:0.05620\tvalidation_1-logloss:0.29426\n",
      "[34]\tvalidation_0-logloss:0.05365\tvalidation_1-logloss:0.29379\n",
      "[35]\tvalidation_0-logloss:0.05127\tvalidation_1-logloss:0.29335\n",
      "[36]\tvalidation_0-logloss:0.04908\tvalidation_1-logloss:0.29320\n",
      "[37]\tvalidation_0-logloss:0.04700\tvalidation_1-logloss:0.29332\n",
      "[38]\tvalidation_0-logloss:0.04506\tvalidation_1-logloss:0.29339\n",
      "[39]\tvalidation_0-logloss:0.04323\tvalidation_1-logloss:0.29323\n",
      "[40]\tvalidation_0-logloss:0.04154\tvalidation_1-logloss:0.29334\n",
      "[41]\tvalidation_0-logloss:0.03994\tvalidation_1-logloss:0.29346\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.1, max_bin=256,\n",
       "              max_cat_to_onehot=4, max_delta_step=0, max_depth=20, max_leaves=0,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=&#x27;()&#x27;,\n",
       "              n_estimators=80, n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n",
       "              random_state=0, reg_alpha=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.1, max_bin=256,\n",
       "              max_cat_to_onehot=4, max_delta_step=0, max_depth=20, max_leaves=0,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=&#x27;()&#x27;,\n",
       "              n_estimators=80, n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n",
       "              random_state=0, reg_alpha=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.1, max_bin=256,\n",
       "              max_cat_to_onehot=4, max_delta_step=0, max_depth=20, max_leaves=0,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=80, n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
       "              random_state=0, reg_alpha=0, ...)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_best_reg = XGBClassifier(max_depth= 20,\n",
    "                             n_estimators= 80, \n",
    "                             learning_rate= 0.1,\n",
    "#                             tree_method='gpu_hist',\n",
    "#                              predictor= 'gpu_predictor',\n",
    "#                              subsample = 0.8,\n",
    "#                              objective = 'binary.logistic',\n",
    "#                              random_state = 42\n",
    "                            )\n",
    "\n",
    "xgb_best_reg.fit(X_pp_avg_train, y_unique_train,\n",
    "    # evaluate loss at each iteration\n",
    "    eval_set=[(X_pp_avg_train,y_unique_train), \n",
    "              (X_pp_avg_val, y_unique_val)\n",
    "             ],  \n",
    "    # stop iterating when eval loss increases 'x' times in a row\n",
    "    early_stopping_rounds=5\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7bbf29e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_best_reg.predict(X_pp_avg_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "aaf686ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4994697542156536"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amex_metric(y_unique_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "667483a8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[09:02:25] /Users/sjoerddewit/code/Yuzhe17/AMEX_default_prediction/xgboost/python-package/build/temp.macosx-12.4-x86_64-3.8/xgboost/src/objective/objective.cc:26: Unknown objective function: `{'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.6, 'eval_metric': 'logloss', 'objective': 'binary:logistic', 'tree_method': 'gpu_hist', 'predictor': 'gpu_predictor', 'random_state': 42}`\nObjective candidate: survival:aft\nObjective candidate: binary:hinge\nObjective candidate: multi:softmax\nObjective candidate: multi:softprob\nObjective candidate: rank:pairwise\nObjective candidate: rank:ndcg\nObjective candidate: rank:map\nObjective candidate: reg:squarederror\nObjective candidate: reg:squaredlogerror\nObjective candidate: reg:logistic\nObjective candidate: binary:logistic\nObjective candidate: binary:logitraw\nObjective candidate: reg:linear\nObjective candidate: reg:pseudohubererror\nObjective candidate: count:poisson\nObjective candidate: survival:cox\nObjective candidate: reg:gamma\nObjective candidate: reg:tweedie\nObjective candidate: reg:absoluteerror\n\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x00000001543fefc5 dmlc::LogMessageFatal::~LogMessageFatal() + 117\n  [bt] (1) 2   libxgboost.dylib                    0x00000001545445d5 xgboost::ObjFunction::Create(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, xgboost::GenericParameter const*) + 1061\n  [bt] (2) 3   libxgboost.dylib                    0x00000001544ef757 xgboost::LearnerConfiguration::ConfigureObjective(xgboost::LearnerTrainParam const&, std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > >*) + 1767\n  [bt] (3) 4   libxgboost.dylib                    0x00000001544e447e xgboost::LearnerConfiguration::Configure() + 1070\n  [bt] (4) 5   libxgboost.dylib                    0x00000001543f4146 XGBoosterBoostedRounds + 102\n  [bt] (5) 6   libffi.dylib                        0x00007ff8231f8882 ffi_call_unix64 + 82\n  [bt] (6) 7   ???                                 0x000000030590e150 0x0 + 12978282832\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m xgb_ \u001b[38;5;241m=\u001b[39m XGBClassifier(xgb_parms)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mxgb_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_pp_avg_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_unique_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# evaluate loss at each iteration\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_pp_avg_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_unique_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_pp_avg_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_unique_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# stop iterating when eval loss increases 5 times in a row\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/xgboost/core.py:584\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    583\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 584\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/xgboost/sklearn.py:1487\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1459\u001b[0m (\n\u001b[1;32m   1460\u001b[0m     model,\n\u001b[1;32m   1461\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1467\u001b[0m )\n\u001b[1;32m   1468\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1469\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1470\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1485\u001b[0m )\n\u001b[0;32m-> 1487\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1499\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1502\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/xgboost/core.py:584\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    583\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 584\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/xgboost/training.py:180\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    168\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    169\u001b[0m         EarlyStopping(rounds\u001b[38;5;241m=\u001b[39mearly_stopping_rounds, maximize\u001b[38;5;241m=\u001b[39mmaximize)\n\u001b[1;32m    170\u001b[0m     )\n\u001b[1;32m    171\u001b[0m cb_container \u001b[38;5;241m=\u001b[39m CallbackContainer(\n\u001b[1;32m    172\u001b[0m     callbacks,\n\u001b[1;32m    173\u001b[0m     metric\u001b[38;5;241m=\u001b[39mmetric_fn,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m     output_margin\u001b[38;5;241m=\u001b[39mcallable(obj) \u001b[38;5;129;01mor\u001b[39;00m metric_fn \u001b[38;5;129;01mis\u001b[39;00m feval,\n\u001b[1;32m    178\u001b[0m )\n\u001b[0;32m--> 180\u001b[0m bst \u001b[38;5;241m=\u001b[39m \u001b[43mcb_container\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbefore_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_iteration, num_boost_round):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/xgboost/callback.py:148\u001b[0m, in \u001b[0;36mCallbackContainer.before_training\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;124;03m'''Function called before training.'''\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m--> 148\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbefore_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_training should return the model\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_cv:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/xgboost/callback.py:350\u001b[0m, in \u001b[0;36mEarlyStopping.before_training\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbefore_training\u001b[39m(\u001b[38;5;28mself\u001b[39m, model: _Model) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _Model:\n\u001b[0;32m--> 350\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarting_round \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_boosted_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/xgboost/core.py:2381\u001b[0m, in \u001b[0;36mBooster.num_boosted_rounds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2379\u001b[0m rounds \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_int()\n\u001b[1;32m   2380\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2381\u001b[0m \u001b[43m_check_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterBoostedRounds\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrounds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2382\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rounds\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/xgboost/core.py:250\u001b[0m, in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \n\u001b[1;32m    241\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[38;5;241m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [09:02:25] /Users/sjoerddewit/code/Yuzhe17/AMEX_default_prediction/xgboost/python-package/build/temp.macosx-12.4-x86_64-3.8/xgboost/src/objective/objective.cc:26: Unknown objective function: `{'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.6, 'eval_metric': 'logloss', 'objective': 'binary:logistic', 'tree_method': 'gpu_hist', 'predictor': 'gpu_predictor', 'random_state': 42}`\nObjective candidate: survival:aft\nObjective candidate: binary:hinge\nObjective candidate: multi:softmax\nObjective candidate: multi:softprob\nObjective candidate: rank:pairwise\nObjective candidate: rank:ndcg\nObjective candidate: rank:map\nObjective candidate: reg:squarederror\nObjective candidate: reg:squaredlogerror\nObjective candidate: reg:logistic\nObjective candidate: binary:logistic\nObjective candidate: binary:logitraw\nObjective candidate: reg:linear\nObjective candidate: reg:pseudohubererror\nObjective candidate: count:poisson\nObjective candidate: survival:cox\nObjective candidate: reg:gamma\nObjective candidate: reg:tweedie\nObjective candidate: reg:absoluteerror\n\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x00000001543fefc5 dmlc::LogMessageFatal::~LogMessageFatal() + 117\n  [bt] (1) 2   libxgboost.dylib                    0x00000001545445d5 xgboost::ObjFunction::Create(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, xgboost::GenericParameter const*) + 1061\n  [bt] (2) 3   libxgboost.dylib                    0x00000001544ef757 xgboost::LearnerConfiguration::ConfigureObjective(xgboost::LearnerTrainParam const&, std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > >*) + 1767\n  [bt] (3) 4   libxgboost.dylib                    0x00000001544e447e xgboost::LearnerConfiguration::Configure() + 1070\n  [bt] (4) 5   libxgboost.dylib                    0x00000001543f4146 XGBoosterBoostedRounds + 102\n  [bt] (5) 6   libffi.dylib                        0x00007ff8231f8882 ffi_call_unix64 + 82\n  [bt] (6) 7   ???                                 0x000000030590e150 0x0 + 12978282832\n\n"
     ]
    }
   ],
   "source": [
    "xgb_ = XGBClassifier(xgb_parms)\n",
    "\n",
    "xgb_.fit(X_pp_avg_train, y_unique_train,\n",
    "    # evaluate loss at each iteration\n",
    "    eval_set=[(X_pp_avg_train,y_unique_train), (X_pp_avg_val, y_unique_val)],  \n",
    "    # stop iterating when eval loss increases 5 times in a row\n",
    "    early_stopping_rounds=7\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc4c3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_.predict(X_pp_avg_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef7b079",
   "metadata": {},
   "outputs": [],
   "source": [
    "amex_metric(y_unique_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ccb7c6",
   "metadata": {},
   "source": [
    "# XG Boost & Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f342799e",
   "metadata": {},
   "source": [
    "https://optuna.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "59fd9105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e04d829c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    param = {\n",
    "        'booster':'gbtree',\n",
    "        'tree_method':'gpu_hist', \n",
    "        \"objective\": \"binary:logistic\",\n",
    "        'lambda': trial.suggest_loguniform(\n",
    "            'lambda', 1e-3, 10.0\n",
    "        ),\n",
    "        'alpha': trial.suggest_loguniform(\n",
    "            'alpha', 1e-3, 10.0\n",
    "        ),\n",
    "        'colsample_bytree': trial.suggest_float(\n",
    "            'colsample_bytree', 0.5,1,step=0.1\n",
    "        ),\n",
    "        'subsample': trial.suggest_float(\n",
    "            'subsample', 0.5,1,step=0.1\n",
    "        ),\n",
    "        'learning_rate': trial.suggest_float(\n",
    "            'learning_rate', 0.001,0.05,step=0.001\n",
    "        ),\n",
    "        'n_estimators': trial.suggest_int(\n",
    "            \"n_estimators\", 80,1000,10\n",
    "        ),\n",
    "        'max_depth': trial.suggest_int(\n",
    "            'max_depth', 2,10,1\n",
    "        ),\n",
    "        'random_state': 99,\n",
    "        'min_child_weight': trial.suggest_int(\n",
    "            'min_child_weight', 1,256,1\n",
    "        ),\n",
    "    }\n",
    "    \n",
    "    model = XGBClassifier(**param, enable_categorical = True) \n",
    "    \n",
    "    model.fit(X_pp_avg_train,y_unique_train)\n",
    "    \n",
    "    preds = pd.DataFrame(model.predict(X_pp_avg_val))\n",
    "    \n",
    "    accuracy = sklearn.metrics.accuracy_score(pd.DataFrame(y_test.reset_index()['target']),preds)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "08cf3adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-06 11:10:46,520]\u001b[0m A new study created in memory with name: no-name-d9f9ab38-710c-46b9-8ba4-301ab2120189\u001b[0m\n",
      "\u001b[33m[W 2022-09-06 11:10:46,713]\u001b[0m Trial 0 failed because of the following error: XGBoostError('[11:10:46] /Users/sjoerddewit/code/Yuzhe17/AMEX_default_prediction/xgboost/python-package/build/temp.macosx-12.4-x86_64-3.8/xgboost/src/gbm/../common/common.h:239: XGBoost version not compiled with GPU support.\\nStack trace:\\n  [bt] (0) 1   libxgboost.dylib                    0x00000001533edfc5 dmlc::LogMessageFatal::~LogMessageFatal() + 117\\n  [bt] (1) 2   libxgboost.dylib                    0x00000001534b5d2e xgboost::gbm::GBTree::ConfigureUpdaters() + 478\\n  [bt] (2) 3   libxgboost.dylib                    0x00000001534b58e1 xgboost::gbm::GBTree::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > > const&) + 1073\\n  [bt] (3) 4   libxgboost.dylib                    0x00000001534d34ee xgboost::LearnerConfiguration::Configure() + 1182\\n  [bt] (4) 5   libxgboost.dylib                    0x00000001534d3839 xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 105\\n  [bt] (5) 6   libxgboost.dylib                    0x00000001533e38aa XGBoosterUpdateOneIter + 138\\n  [bt] (6) 7   libffi.dylib                        0x00007ff8231f8882 ffi_call_unix64 + 82\\n  [bt] (7) 8   ???                                 0x00000003062cf020 0x0 + 12988510240\\n\\n')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sjoerddewit/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/fk/b6p2kjv927g82pgl5sgqrr7w0000gn/T/ipykernel_34442/2576386829.py\", line 36, in objective\n",
      "    model.fit(X_pp_avg_train,y_unique_train)\n",
      "  File \"/Users/sjoerddewit/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/xgboost/core.py\", line 584, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/sjoerddewit/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1487, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/sjoerddewit/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/xgboost/core.py\", line 584, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/sjoerddewit/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/sjoerddewit/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/xgboost/core.py\", line 1840, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/sjoerddewit/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/xgboost/core.py\", line 250, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:10:46] /Users/sjoerddewit/code/Yuzhe17/AMEX_default_prediction/xgboost/python-package/build/temp.macosx-12.4-x86_64-3.8/xgboost/src/gbm/../common/common.h:239: XGBoost version not compiled with GPU support.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x00000001533edfc5 dmlc::LogMessageFatal::~LogMessageFatal() + 117\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x00000001534b5d2e xgboost::gbm::GBTree::ConfigureUpdaters() + 478\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001534b58e1 xgboost::gbm::GBTree::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > > const&) + 1073\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x00000001534d34ee xgboost::LearnerConfiguration::Configure() + 1182\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x00000001534d3839 xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 105\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x00000001533e38aa XGBoosterUpdateOneIter + 138\n",
      "  [bt] (6) 7   libffi.dylib                        0x00007ff8231f8882 ffi_call_unix64 + 82\n",
      "  [bt] (7) 8   ???                                 0x00000003062cf020 0x0 + 12988510240\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[11:10:46] /Users/sjoerddewit/code/Yuzhe17/AMEX_default_prediction/xgboost/python-package/build/temp.macosx-12.4-x86_64-3.8/xgboost/src/gbm/../common/common.h:239: XGBoost version not compiled with GPU support.\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x00000001533edfc5 dmlc::LogMessageFatal::~LogMessageFatal() + 117\n  [bt] (1) 2   libxgboost.dylib                    0x00000001534b5d2e xgboost::gbm::GBTree::ConfigureUpdaters() + 478\n  [bt] (2) 3   libxgboost.dylib                    0x00000001534b58e1 xgboost::gbm::GBTree::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > > const&) + 1073\n  [bt] (3) 4   libxgboost.dylib                    0x00000001534d34ee xgboost::LearnerConfiguration::Configure() + 1182\n  [bt] (4) 5   libxgboost.dylib                    0x00000001534d3839 xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 105\n  [bt] (5) 6   libxgboost.dylib                    0x00000001533e38aa XGBoosterUpdateOneIter + 138\n  [bt] (6) 7   libffi.dylib                        0x00007ff8231f8882 ffi_call_unix64 + 82\n  [bt] (7) 8   ???                                 0x00000003062cf020 0x0 + 12988510240\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/optuna/study/study.py:419\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    317\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    325\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \n\u001b[1;32m    328\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as CircleCI).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/optuna/study/_optimize.py:234\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    230\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    233\u001b[0m ):\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Input \u001b[0;32mIn [48]\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      3\u001b[0m param \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbooster\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgbtree\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtree_method\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu_hist\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     ),\n\u001b[1;32m     32\u001b[0m }\n\u001b[1;32m     34\u001b[0m model \u001b[38;5;241m=\u001b[39m XGBClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparam, enable_categorical \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \n\u001b[0;32m---> 36\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_pp_avg_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_unique_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m preds \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(model\u001b[38;5;241m.\u001b[39mpredict(X_pp_avg_val))\n\u001b[1;32m     40\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m sklearn\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39maccuracy_score(pd\u001b[38;5;241m.\u001b[39mDataFrame(y_test\u001b[38;5;241m.\u001b[39mreset_index()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m]),preds)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/xgboost/core.py:584\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    583\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 584\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/xgboost/sklearn.py:1487\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1459\u001b[0m (\n\u001b[1;32m   1460\u001b[0m     model,\n\u001b[1;32m   1461\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1467\u001b[0m )\n\u001b[1;32m   1468\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1469\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1470\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1485\u001b[0m )\n\u001b[0;32m-> 1487\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1499\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1502\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/xgboost/core.py:584\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    583\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 584\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/xgboost/core.py:1840\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1837\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_features(dtrain)\n\u001b[1;32m   1839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1840\u001b[0m     \u001b[43m_check_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1841\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1842\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1843\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1844\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/xgboost/core.py:250\u001b[0m, in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \n\u001b[1;32m    241\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[38;5;241m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [11:10:46] /Users/sjoerddewit/code/Yuzhe17/AMEX_default_prediction/xgboost/python-package/build/temp.macosx-12.4-x86_64-3.8/xgboost/src/gbm/../common/common.h:239: XGBoost version not compiled with GPU support.\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x00000001533edfc5 dmlc::LogMessageFatal::~LogMessageFatal() + 117\n  [bt] (1) 2   libxgboost.dylib                    0x00000001534b5d2e xgboost::gbm::GBTree::ConfigureUpdaters() + 478\n  [bt] (2) 3   libxgboost.dylib                    0x00000001534b58e1 xgboost::gbm::GBTree::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > > const&) + 1073\n  [bt] (3) 4   libxgboost.dylib                    0x00000001534d34ee xgboost::LearnerConfiguration::Configure() + 1182\n  [bt] (4) 5   libxgboost.dylib                    0x00000001534d3839 xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 105\n  [bt] (5) 6   libxgboost.dylib                    0x00000001533e38aa XGBoosterUpdateOneIter + 138\n  [bt] (6) 7   libffi.dylib                        0x00007ff8231f8882 ffi_call_unix64 + 82\n  [bt] (7) 8   ???                                 0x00000003062cf020 0x0 + 12988510240\n\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cc770f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3afbac6",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8199406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as ctb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4e60656d",
   "metadata": {},
   "outputs": [
    {
     "ename": "CatBoostError",
     "evalue": "Bad value for num_feature[non_default_doc_idx=0,feature_idx=51]=\"CO\": Cannot convert 'b'CO'' to float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m_catboost.pyx:2275\u001b[0m, in \u001b[0;36m_catboost.get_float_feature\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:1128\u001b[0m, in \u001b[0;36m_catboost._FloatOrNan\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:949\u001b[0m, in \u001b[0;36m_catboost._FloatOrNanFromString\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert 'b'CO'' to float",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [106]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model_CBC \u001b[38;5;241m=\u001b[39m ctb\u001b[38;5;241m.\u001b[39mCatBoostClassifier(iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m, \n\u001b[1;32m      2\u001b[0m                                    random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m22\u001b[39m, \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#                                    task_type = 'GPU'\u001b[39;00m\n\u001b[1;32m      4\u001b[0m                                   )\n\u001b[0;32m----> 6\u001b[0m \u001b[43mmodel_CBC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/catboost/core.py:5007\u001b[0m, in \u001b[0;36mCatBoostClassifier.fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m   5005\u001b[0m     CatBoostClassifier\u001b[38;5;241m.\u001b[39m_check_is_compatible_loss(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m-> 5007\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5008\u001b[0m \u001b[43m          \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5009\u001b[0m \u001b[43m          \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5010\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/catboost/core.py:2262\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, PATH_TYPES \u001b[38;5;241m+\u001b[39m (Pool,)):\n\u001b[1;32m   2260\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my may be None only when X is an instance of catboost.Pool or string\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2262\u001b[0m train_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_train_params\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2265\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubgroup_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpairs_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2266\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2268\u001b[0m \u001b[43m    \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2269\u001b[0m \u001b[43m    \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m   2271\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2272\u001b[0m params \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   2273\u001b[0m train_pool \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/catboost/core.py:2148\u001b[0m, in \u001b[0;36mCatBoost._prepare_train_params\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks)\u001b[0m\n\u001b[1;32m   2145\u001b[0m text_features \u001b[38;5;241m=\u001b[39m _process_feature_indices(text_features, X, params, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_features\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   2146\u001b[0m embedding_features \u001b[38;5;241m=\u001b[39m _process_feature_indices(embedding_features, X, params, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding_features\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 2148\u001b[0m train_pool \u001b[38;5;241m=\u001b[39m \u001b[43m_build_train_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2149\u001b[0m \u001b[43m                               \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2150\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train_pool\u001b[38;5;241m.\u001b[39mis_empty_:\n\u001b[1;32m   2152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX is empty.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/catboost/core.py:1430\u001b[0m, in \u001b[0;36m_build_train_pool\u001b[0;34m(X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, column_description)\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1429\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my has not initialized in fit(): X is not catboost.Pool object, y must be not None in fit().\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1430\u001b[0m     train_pool \u001b[38;5;241m=\u001b[39m \u001b[43mPool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1431\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mgroup_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgroup_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpairs_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaseline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1432\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_pool\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/catboost/core.py:790\u001b[0m, in \u001b[0;36mPool.__init__\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, column_description, pairs, delimiter, has_header, ignore_csv_quoting, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(feature_names, PATH_TYPES):\n\u001b[1;32m    785\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\n\u001b[1;32m    786\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_names must be None or have non-string type when the pool is created from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    787\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython objects.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    788\u001b[0m             )\n\u001b[0;32m--> 790\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_tags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;28msuper\u001b[39m(Pool, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/catboost/core.py:1411\u001b[0m, in \u001b[0;36mPool._init\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_tags \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1410\u001b[0m     feature_tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_transform_tags(feature_tags, feature_names)\n\u001b[0;32m-> 1411\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1412\u001b[0m \u001b[43m                \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_tags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_count\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m_catboost.pyx:3941\u001b[0m, in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:3991\u001b[0m, in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:3807\u001b[0m, in \u001b[0;36m_catboost._PoolBase._init_features_order_layout_pool\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:2775\u001b[0m, in \u001b[0;36m_catboost._set_features_order_data_pd_data_frame\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:2316\u001b[0m, in \u001b[0;36m_catboost.create_num_factor_data\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:2277\u001b[0m, in \u001b[0;36m_catboost.get_float_feature\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCatBoostError\u001b[0m: Bad value for num_feature[non_default_doc_idx=0,feature_idx=51]=\"CO\": Cannot convert 'b'CO'' to float"
     ]
    }
   ],
   "source": [
    "model_CBC = ctb.CatBoostClassifier(iterations=5000, \n",
    "                                   random_state=22, \n",
    "#                                    task_type = 'GPU'\n",
    "                                  )\n",
    "\n",
    "model_CBC.fit(train_x, train_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "50cb9425",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_CBC.predict(X_pp_avg_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f1795de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5067162455164427"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amex_metric(y_unique_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef438b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0e8a2175",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "98cc6569",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'B_30_last'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [98]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mB_30_last\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/pandas/core/generic.py:5575\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5569\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   5570\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   5571\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   5572\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5573\u001b[0m ):\n\u001b[1;32m   5574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 5575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'B_30_last'"
     ]
    }
   ],
   "source": [
    "df.B_30_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1969aab2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'B_30_last'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'B_30_last'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [95]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m le_encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m categorical_feature \u001b[38;5;129;01min\u001b[39;00m cat_features:\n\u001b[0;32m---> 18\u001b[0m     df[categorical_feature] \u001b[38;5;241m=\u001b[39m le_encoder\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     19\u001b[0m     X_pp_avg_val[categorical_feature] \u001b[38;5;241m=\u001b[39m le_encoder\u001b[38;5;241m.\u001b[39mtransform(X_pp_avg_val[categorical_feature])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/AMEX_default_prediction/lib/python3.8/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'B_30_last'"
     ]
    }
   ],
   "source": [
    "features = X_pp_avg_val.columns.to_list()\n",
    "cat_features = [\n",
    "    \"B_30\",\n",
    "    \"B_38\",\n",
    "    \"D_114\",\n",
    "    \"D_116\",\n",
    "    \"D_117\",\n",
    "    \"D_120\",\n",
    "    \"D_126\",\n",
    "    \"D_63\",\n",
    "    \"D_64\",\n",
    "    \"D_66\",\n",
    "    \"D_68\"\n",
    "]\n",
    "cat_features = [f\"{cf}_last\" for cf in cat_features]\n",
    "le_encoder = LabelEncoder()\n",
    "for categorical_feature in cat_features:\n",
    "    df[categorical_feature] = le_encoder.fit_transform(df[categorical_feature])\n",
    "    X_pp_avg_val[categorical_feature] = le_encoder.transform(X_pp_avg_val[categorical_feature])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fcce770d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Fold 0 ******* \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cat_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [90]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m tr_y, val_y \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     13\u001b[0m     train_y\u001b[38;5;241m.\u001b[39miloc[train_ind]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     14\u001b[0m     train_y\u001b[38;5;241m.\u001b[39miloc[val_ind]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     17\u001b[0m clf \u001b[38;5;241m=\u001b[39m ctb\u001b[38;5;241m.\u001b[39mCatBoostClassifier(iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m22\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(tr_x, tr_y, eval_set\u001b[38;5;241m=\u001b[39m[(val_x, val_y)], cat_features\u001b[38;5;241m=\u001b[39m\u001b[43mcat_features\u001b[49m,  verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     19\u001b[0m preds \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict_proba(val_x)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     20\u001b[0m y_oof[val_ind] \u001b[38;5;241m=\u001b[39m y_oof[val_ind] \u001b[38;5;241m+\u001b[39m preds\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cat_features' is not defined"
     ]
    }
   ],
   "source": [
    "N_FOLDS = 5\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=22)\n",
    "y_oof = np.zeros(train_x.shape[0])\n",
    "y_test = np.zeros(X_pp_avg_val.shape[0])\n",
    "ix = 0\n",
    "for train_ind, val_ind in skf.split(train_x, train_y):\n",
    "    print(f\"******* Fold {ix} ******* \")\n",
    "    tr_x, val_x = (\n",
    "        train_x.iloc[train_ind].reset_index(drop=True),\n",
    "        train_x.iloc[val_ind].reset_index(drop=True),\n",
    "    )\n",
    "    tr_y, val_y = (\n",
    "        train_y.iloc[train_ind].reset_index(drop=True),\n",
    "        train_y.iloc[val_ind].reset_index(drop=True),\n",
    "    )\n",
    "\n",
    "    clf = ctb.CatBoostClassifier(iterations=5000, random_state=22)\n",
    "    clf.fit(tr_x, tr_y, eval_set=[(val_x, val_y)], cat_features=cat_features,  verbose=100)\n",
    "    preds = clf.predict_proba(val_x)[:, 1]\n",
    "    y_oof[val_ind] = y_oof[val_ind] + preds\n",
    "\n",
    "    preds_test = clf.predict_proba(test)[:, 1]\n",
    "    y_test = y_test + preds_test / N_FOLDS\n",
    "    ix = ix + 1\n",
    "y_pred = train_y.copy(deep=True)\n",
    "y_pred = y_pred.rename(columns={\"target\": \"prediction\"})\n",
    "y_pred[\"prediction\"] = y_oof\n",
    "val_score = amex_metric(train_y, y_pred)\n",
    "print(f\"Amex metric: {val_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94f2ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
