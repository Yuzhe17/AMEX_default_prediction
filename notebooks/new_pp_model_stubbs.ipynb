{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, cross_val_predict, learning_curve,\\\n",
    "train_test_split, GridSearchCV, RandomizedSearchCV, train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, OneHotEncoder, FunctionTransformer, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import plot_confusion_matrix, classification_report, precision_recall_curve\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, SGDRegressor, SGDClassifier, Ridge, RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.compose import make_column_selector\n",
    "\n",
    "## pipeline stuff\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, make_union\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer, make_column_selector\n",
    "from sklearn import set_config; set_config(display='diagram')\n",
    "\n",
    "\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = ['B_30', \n",
    "            'B_38', \n",
    "            'D_114', \n",
    "            'D_116', \n",
    "            'D_117', \n",
    "            'D_120', \n",
    "            'D_126', \n",
    "            'D_63', \n",
    "            'D_64', \n",
    "            'D_66', \n",
    "            'D_68']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pay = pd.read_csv(\"/home/slawa/code/code-rep0/projects/data/payer_data_41940.csv\", index_col=[0])\n",
    "df_def = pd.read_csv(\"/home/slawa/code/code-rep0/projects/data/defaulter_data_13364.csv\", index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pay = df_pay.groupby('customer_ID').mean()\n",
    "target_def = df_def.groupby('customer_ID').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pay['target'] = int(0)\n",
    "target_def['target'] = int(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.concat([target_pay, target_def])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target.loc[:,'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_pay, df_def])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"c_PD_239\"]=df[\"D_39\"]/(df[\"P_2\"]*(-1)+0.0001)\n",
    "df[\"c_PB_29\"]=df[\"P_2\"]*(-1)/(df[\"B_9\"]*(1)+0.0001)\n",
    "df[\"c_PR_21\"]=df[\"P_2\"]*(-1)/(df[\"R_1\"]+0.0001)\n",
    "\n",
    "df[\"c_BBBB\"]=(df[\"B_9\"]+0.001)/(df[\"B_23\"]+df[\"B_3\"]+0.0001)\n",
    "df[\"c_BBBB1\"]=(df[\"B_33\"]*(-1))+(df[\"B_18\"]*(-1)+df[\"S_25\"]*(1)+0.0001)\n",
    "df[\"c_BBBB2\"]=(df[\"B_19\"]+df[\"B_20\"]+df[\"B_4\"]+0.0001)\n",
    "\n",
    "df[\"c_RRR0\"]=(df[\"R_3\"]+0.001)/(df[\"R_2\"]+df[\"R_4\"]+0.0001)\n",
    "df[\"c_RRR1\"]=(df[\"D_62\"]+0.001)/(df[\"D_112\"]+df[\"R_27\"]+0.0001)\n",
    "\n",
    "df[\"c_PD_348\"]=df[\"D_48\"]/(df[\"P_3\"]+0.0001)\n",
    "df[\"c_PD_355\"]=df[\"D_55\"]/(df[\"P_3\"]+0.0001)\n",
    "\n",
    "df[\"c_PD_439\"]=df[\"D_39\"]/(df[\"P_4\"]+0.0001)\n",
    "df[\"c_PB_49\"]=df[\"B_9\"]/(df[\"P_4\"]+0.0001)\n",
    "df[\"c_PR_41\"]=df[\"R_1\"]/(df[\"P_4\"]+0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>S_2</th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>...</th>\n",
       "      <th>c_BBBB</th>\n",
       "      <th>c_BBBB1</th>\n",
       "      <th>c_BBBB2</th>\n",
       "      <th>c_RRR0</th>\n",
       "      <th>c_RRR1</th>\n",
       "      <th>c_PD_348</th>\n",
       "      <th>c_PD_355</th>\n",
       "      <th>c_PD_439</th>\n",
       "      <th>c_PB_49</th>\n",
       "      <th>c_PR_41</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e5a854a3211e83db521500e8b70360fe9670af1df90401...</td>\n",
       "      <td>2018-01-27</td>\n",
       "      <td>0.367170</td>\n",
       "      <td>0.005127</td>\n",
       "      <td>0.008564</td>\n",
       "      <td>1.006915</td>\n",
       "      <td>0.009815</td>\n",
       "      <td>0.226954</td>\n",
       "      <td>0.003249</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240582</td>\n",
       "      <td>-0.719884</td>\n",
       "      <td>0.026376</td>\n",
       "      <td>93.527964</td>\n",
       "      <td>0.041132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005312</td>\n",
       "      <td>0.002995</td>\n",
       "      <td>0.010169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e5a854a3211e83db521500e8b70360fe9670af1df90401...</td>\n",
       "      <td>2018-02-22</td>\n",
       "      <td>0.393798</td>\n",
       "      <td>0.008609</td>\n",
       "      <td>0.014054</td>\n",
       "      <td>1.000013</td>\n",
       "      <td>0.001827</td>\n",
       "      <td>0.222864</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>0.006139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222950</td>\n",
       "      <td>-0.726073</td>\n",
       "      <td>0.069788</td>\n",
       "      <td>106.959299</td>\n",
       "      <td>0.037138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008921</td>\n",
       "      <td>0.008784</td>\n",
       "      <td>0.001893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e3ce8ab83161700aab304eb01f8b23385bea28dae59c8a...</td>\n",
       "      <td>2017-03-08</td>\n",
       "      <td>0.977155</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.819058</td>\n",
       "      <td>0.006936</td>\n",
       "      <td>0.313585</td>\n",
       "      <td>0.001432</td>\n",
       "      <td>0.014320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106694</td>\n",
       "      <td>-1.027956</td>\n",
       "      <td>0.087947</td>\n",
       "      <td>47.443315</td>\n",
       "      <td>0.378304</td>\n",
       "      <td>0.118312</td>\n",
       "      <td>0.141249</td>\n",
       "      <td>4.563409</td>\n",
       "      <td>5.537089</td>\n",
       "      <td>14.310557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e3ce8ab83161700aab304eb01f8b23385bea28dae59c8a...</td>\n",
       "      <td>2018-03-13</td>\n",
       "      <td>1.000395</td>\n",
       "      <td>0.186044</td>\n",
       "      <td>0.017830</td>\n",
       "      <td>0.813150</td>\n",
       "      <td>0.007263</td>\n",
       "      <td>0.123836</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055488</td>\n",
       "      <td>-1.040972</td>\n",
       "      <td>0.052233</td>\n",
       "      <td>0.839227</td>\n",
       "      <td>0.748211</td>\n",
       "      <td>0.049795</td>\n",
       "      <td>0.261346</td>\n",
       "      <td>20.591684</td>\n",
       "      <td>0.021347</td>\n",
       "      <td>0.803855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e4531d93a40fe3892fd93c5d3991243acac7cfb90d2ce9...</td>\n",
       "      <td>2017-11-21</td>\n",
       "      <td>0.434304</td>\n",
       "      <td>0.009313</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>0.819881</td>\n",
       "      <td>0.008974</td>\n",
       "      <td>0.177063</td>\n",
       "      <td>0.007866</td>\n",
       "      <td>0.005926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.229565</td>\n",
       "      <td>-1.045192</td>\n",
       "      <td>0.088544</td>\n",
       "      <td>15.652176</td>\n",
       "      <td>0.091147</td>\n",
       "      <td>1.350078</td>\n",
       "      <td>0.689079</td>\n",
       "      <td>6.564925</td>\n",
       "      <td>1.647892</td>\n",
       "      <td>6.325904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13359</th>\n",
       "      <td>d7e2f69aa41106bb7413e9b3dcd28e1a0a074d2685d26a...</td>\n",
       "      <td>2017-11-18</td>\n",
       "      <td>0.342782</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.026842</td>\n",
       "      <td>0.135342</td>\n",
       "      <td>0.008224</td>\n",
       "      <td>0.241999</td>\n",
       "      <td>0.006360</td>\n",
       "      <td>0.202902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.271374</td>\n",
       "      <td>0.702368</td>\n",
       "      <td>0.547280</td>\n",
       "      <td>105.828241</td>\n",
       "      <td>0.058923</td>\n",
       "      <td>2.585518</td>\n",
       "      <td>2.234734</td>\n",
       "      <td>18.016712</td>\n",
       "      <td>57.799648</td>\n",
       "      <td>4.318215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13360</th>\n",
       "      <td>d7e2f69aa41106bb7413e9b3dcd28e1a0a074d2685d26a...</td>\n",
       "      <td>2017-12-19</td>\n",
       "      <td>0.339534</td>\n",
       "      <td>0.031273</td>\n",
       "      <td>0.023687</td>\n",
       "      <td>0.139861</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.232908</td>\n",
       "      <td>0.009484</td>\n",
       "      <td>0.198701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223498</td>\n",
       "      <td>0.697835</td>\n",
       "      <td>0.555627</td>\n",
       "      <td>119.744388</td>\n",
       "      <td>0.019650</td>\n",
       "      <td>1.864197</td>\n",
       "      <td>1.670538</td>\n",
       "      <td>8.348961</td>\n",
       "      <td>24.184250</td>\n",
       "      <td>0.532409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13361</th>\n",
       "      <td>d7e2f69aa41106bb7413e9b3dcd28e1a0a074d2685d26a...</td>\n",
       "      <td>2018-01-19</td>\n",
       "      <td>0.226843</td>\n",
       "      <td>0.031205</td>\n",
       "      <td>0.021618</td>\n",
       "      <td>0.146228</td>\n",
       "      <td>0.008076</td>\n",
       "      <td>0.235040</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.195985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198715</td>\n",
       "      <td>0.704181</td>\n",
       "      <td>0.567496</td>\n",
       "      <td>36.766743</td>\n",
       "      <td>0.023943</td>\n",
       "      <td>4.279048</td>\n",
       "      <td>3.889089</td>\n",
       "      <td>11.548969</td>\n",
       "      <td>29.617420</td>\n",
       "      <td>2.989068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13362</th>\n",
       "      <td>d7e2f69aa41106bb7413e9b3dcd28e1a0a074d2685d26a...</td>\n",
       "      <td>2018-02-16</td>\n",
       "      <td>0.230107</td>\n",
       "      <td>0.035024</td>\n",
       "      <td>0.021670</td>\n",
       "      <td>0.226883</td>\n",
       "      <td>0.509827</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001564</td>\n",
       "      <td>0.175962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138995</td>\n",
       "      <td>0.767887</td>\n",
       "      <td>0.717766</td>\n",
       "      <td>85.181959</td>\n",
       "      <td>0.049961</td>\n",
       "      <td>3.732564</td>\n",
       "      <td>3.156621</td>\n",
       "      <td>13.324742</td>\n",
       "      <td>22.332714</td>\n",
       "      <td>193.963126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13363</th>\n",
       "      <td>d7e2f69aa41106bb7413e9b3dcd28e1a0a074d2685d26a...</td>\n",
       "      <td>2018-03-26</td>\n",
       "      <td>0.165446</td>\n",
       "      <td>0.238344</td>\n",
       "      <td>0.051775</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.505180</td>\n",
       "      <td>0.177076</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.140062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.413916</td>\n",
       "      <td>0.762866</td>\n",
       "      <td>0.799690</td>\n",
       "      <td>0.228610</td>\n",
       "      <td>2.283222</td>\n",
       "      <td>3.759083</td>\n",
       "      <td>3.351483</td>\n",
       "      <td>70.388760</td>\n",
       "      <td>54.993870</td>\n",
       "      <td>149.192213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55304 rows × 203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             customer_ID         S_2  \\\n",
       "0      e5a854a3211e83db521500e8b70360fe9670af1df90401...  2018-01-27   \n",
       "1      e5a854a3211e83db521500e8b70360fe9670af1df90401...  2018-02-22   \n",
       "2      e3ce8ab83161700aab304eb01f8b23385bea28dae59c8a...  2017-03-08   \n",
       "3      e3ce8ab83161700aab304eb01f8b23385bea28dae59c8a...  2018-03-13   \n",
       "4      e4531d93a40fe3892fd93c5d3991243acac7cfb90d2ce9...  2017-11-21   \n",
       "...                                                  ...         ...   \n",
       "13359  d7e2f69aa41106bb7413e9b3dcd28e1a0a074d2685d26a...  2017-11-18   \n",
       "13360  d7e2f69aa41106bb7413e9b3dcd28e1a0a074d2685d26a...  2017-12-19   \n",
       "13361  d7e2f69aa41106bb7413e9b3dcd28e1a0a074d2685d26a...  2018-01-19   \n",
       "13362  d7e2f69aa41106bb7413e9b3dcd28e1a0a074d2685d26a...  2018-02-16   \n",
       "13363  d7e2f69aa41106bb7413e9b3dcd28e1a0a074d2685d26a...  2018-03-26   \n",
       "\n",
       "            P_2      D_39       B_1       B_2       R_1       S_3      D_41  \\\n",
       "0      0.367170  0.005127  0.008564  1.006915  0.009815  0.226954  0.003249   \n",
       "1      0.393798  0.008609  0.014054  1.000013  0.001827  0.222864  0.003984   \n",
       "2      0.977155  0.002212  0.000951  0.819058  0.006936  0.313585  0.001432   \n",
       "3      1.000395  0.186044  0.017830  0.813150  0.007263  0.123836  0.003332   \n",
       "4      0.434304  0.009313  0.001116  0.819881  0.008974  0.177063  0.007866   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "13359  0.342782  0.034313  0.026842  0.135342  0.008224  0.241999  0.006360   \n",
       "13360  0.339534  0.031273  0.023687  0.139861  0.001994  0.232908  0.009484   \n",
       "13361  0.226843  0.031205  0.021618  0.146228  0.008076  0.235040  0.003757   \n",
       "13362  0.230107  0.035024  0.021670  0.226883  0.509827       NaN  0.001564   \n",
       "13363  0.165446  0.238344  0.051775  0.000076  0.505180  0.177076  0.001176   \n",
       "\n",
       "            B_3  ...    c_BBBB   c_BBBB1   c_BBBB2      c_RRR0    c_RRR1  \\\n",
       "0      0.000318  ...  0.240582 -0.719884  0.026376   93.527964  0.041132   \n",
       "1      0.006139  ...  0.222950 -0.726073  0.069788  106.959299  0.037138   \n",
       "2      0.014320  ...  0.106694 -1.027956  0.087947   47.443315  0.378304   \n",
       "3      0.000018  ...  0.055488 -1.040972  0.052233    0.839227  0.748211   \n",
       "4      0.005926  ...  0.229565 -1.045192  0.088544   15.652176  0.091147   \n",
       "...         ...  ...       ...       ...       ...         ...       ...   \n",
       "13359  0.202902  ...  0.271374  0.702368  0.547280  105.828241  0.058923   \n",
       "13360  0.198701  ...  0.223498  0.697835  0.555627  119.744388  0.019650   \n",
       "13361  0.195985  ...  0.198715  0.704181  0.567496   36.766743  0.023943   \n",
       "13362  0.175962  ...  0.138995  0.767887  0.717766   85.181959  0.049961   \n",
       "13363  0.140062  ...  0.413916  0.762866  0.799690    0.228610  2.283222   \n",
       "\n",
       "       c_PD_348  c_PD_355   c_PD_439    c_PB_49     c_PR_41  \n",
       "0           NaN       NaN   0.005312   0.002995    0.010169  \n",
       "1           NaN       NaN   0.008921   0.008784    0.001893  \n",
       "2      0.118312  0.141249   4.563409   5.537089   14.310557  \n",
       "3      0.049795  0.261346  20.591684   0.021347    0.803855  \n",
       "4      1.350078  0.689079   6.564925   1.647892    6.325904  \n",
       "...         ...       ...        ...        ...         ...  \n",
       "13359  2.585518  2.234734  18.016712  57.799648    4.318215  \n",
       "13360  1.864197  1.670538   8.348961  24.184250    0.532409  \n",
       "13361  4.279048  3.889089  11.548969  29.617420    2.989068  \n",
       "13362  3.732564  3.156621  13.324742  22.332714  193.963126  \n",
       "13363  3.759083  3.351483  70.388760  54.993870  149.192213  \n",
       "\n",
       "[55304 rows x 203 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(['customer_ID', 'S_2'], axis = 1).columns.to_list() # get all feature names, except customer_ID and dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = [feature for feature in features if feature not in cat_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num_agg = df.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last']) # give summary statistics for each numerical feature\n",
    "train_num_agg.columns = ['_'.join(x) for x in train_num_agg.columns] # join the column name tuples to a single name\n",
    "train_num_agg.reset_index(inplace = True) # get the customer_ID in as a column again and reset index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>P_2_mean</th>\n",
       "      <th>P_2_std</th>\n",
       "      <th>P_2_min</th>\n",
       "      <th>P_2_max</th>\n",
       "      <th>P_2_last</th>\n",
       "      <th>D_39_mean</th>\n",
       "      <th>D_39_std</th>\n",
       "      <th>D_39_min</th>\n",
       "      <th>D_39_max</th>\n",
       "      <th>...</th>\n",
       "      <th>c_PB_49_mean</th>\n",
       "      <th>c_PB_49_std</th>\n",
       "      <th>c_PB_49_min</th>\n",
       "      <th>c_PB_49_max</th>\n",
       "      <th>c_PB_49_last</th>\n",
       "      <th>c_PR_41_mean</th>\n",
       "      <th>c_PR_41_std</th>\n",
       "      <th>c_PR_41_min</th>\n",
       "      <th>c_PR_41_max</th>\n",
       "      <th>c_PR_41_last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000919ba92d9a04c28e1e49f6cd855ca36e1df7c79cc05...</td>\n",
       "      <td>0.499402</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.476616</td>\n",
       "      <td>0.522344</td>\n",
       "      <td>0.498361</td>\n",
       "      <td>0.470466</td>\n",
       "      <td>0.198861</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.830081</td>\n",
       "      <td>...</td>\n",
       "      <td>225.297543</td>\n",
       "      <td>213.187017</td>\n",
       "      <td>64.916394</td>\n",
       "      <td>696.014237</td>\n",
       "      <td>125.073946</td>\n",
       "      <td>10.058885</td>\n",
       "      <td>22.090925</td>\n",
       "      <td>0.001433</td>\n",
       "      <td>67.413339</td>\n",
       "      <td>0.259988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00158cf08fcf7ec058529dd71b4cff04ce89314e79840b...</td>\n",
       "      <td>0.691427</td>\n",
       "      <td>0.024675</td>\n",
       "      <td>0.666900</td>\n",
       "      <td>0.733644</td>\n",
       "      <td>0.707521</td>\n",
       "      <td>0.026813</td>\n",
       "      <td>0.080476</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.294493</td>\n",
       "      <td>...</td>\n",
       "      <td>1.827795</td>\n",
       "      <td>3.524579</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>11.108380</td>\n",
       "      <td>3.967306</td>\n",
       "      <td>1.004138</td>\n",
       "      <td>1.743268</td>\n",
       "      <td>0.001401</td>\n",
       "      <td>4.546990</td>\n",
       "      <td>3.423076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0018753794d55ff4ab24aaa7f8e65d504fd1efbf04e369...</td>\n",
       "      <td>0.281522</td>\n",
       "      <td>0.090988</td>\n",
       "      <td>0.198344</td>\n",
       "      <td>0.498234</td>\n",
       "      <td>0.325086</td>\n",
       "      <td>0.095091</td>\n",
       "      <td>0.185570</td>\n",
       "      <td>0.001569</td>\n",
       "      <td>0.567713</td>\n",
       "      <td>...</td>\n",
       "      <td>316.086714</td>\n",
       "      <td>580.285457</td>\n",
       "      <td>0.613235</td>\n",
       "      <td>2192.639080</td>\n",
       "      <td>30.993720</td>\n",
       "      <td>24.989575</td>\n",
       "      <td>42.628358</td>\n",
       "      <td>0.006441</td>\n",
       "      <td>114.600555</td>\n",
       "      <td>0.949760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0044d8693a5c204d5e22297b11e566d9de1c1610899d20...</td>\n",
       "      <td>0.863033</td>\n",
       "      <td>0.035847</td>\n",
       "      <td>0.808965</td>\n",
       "      <td>0.915033</td>\n",
       "      <td>0.878732</td>\n",
       "      <td>0.005821</td>\n",
       "      <td>0.002665</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>0.009564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.895997</td>\n",
       "      <td>0.657292</td>\n",
       "      <td>0.160506</td>\n",
       "      <td>2.215508</td>\n",
       "      <td>2.215508</td>\n",
       "      <td>0.837358</td>\n",
       "      <td>0.695346</td>\n",
       "      <td>0.004019</td>\n",
       "      <td>2.406603</td>\n",
       "      <td>2.406603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00597bc3d552264d841bd1a52cfaf3ebe40755f96d85a5...</td>\n",
       "      <td>0.343063</td>\n",
       "      <td>0.047509</td>\n",
       "      <td>0.220225</td>\n",
       "      <td>0.378734</td>\n",
       "      <td>0.371411</td>\n",
       "      <td>0.164823</td>\n",
       "      <td>0.201824</td>\n",
       "      <td>0.009121</td>\n",
       "      <td>0.803373</td>\n",
       "      <td>...</td>\n",
       "      <td>298.391624</td>\n",
       "      <td>511.164682</td>\n",
       "      <td>59.923864</td>\n",
       "      <td>1947.667927</td>\n",
       "      <td>122.563743</td>\n",
       "      <td>127.859961</td>\n",
       "      <td>221.530941</td>\n",
       "      <td>27.114767</td>\n",
       "      <td>844.638848</td>\n",
       "      <td>54.379913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4570</th>\n",
       "      <td>ffbdeb593c97bc39bf6228e7236796cf5dcd530ef73014...</td>\n",
       "      <td>0.800766</td>\n",
       "      <td>0.054486</td>\n",
       "      <td>0.665637</td>\n",
       "      <td>0.855915</td>\n",
       "      <td>0.823051</td>\n",
       "      <td>0.551746</td>\n",
       "      <td>0.366059</td>\n",
       "      <td>0.004717</td>\n",
       "      <td>1.215695</td>\n",
       "      <td>...</td>\n",
       "      <td>1.925914</td>\n",
       "      <td>3.953065</td>\n",
       "      <td>0.031917</td>\n",
       "      <td>14.654292</td>\n",
       "      <td>0.839985</td>\n",
       "      <td>2.738269</td>\n",
       "      <td>4.365143</td>\n",
       "      <td>0.241016</td>\n",
       "      <td>14.539556</td>\n",
       "      <td>0.907417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4571</th>\n",
       "      <td>ffbff903bdd4104397101a428a4c5c4daa4d28e26f8716...</td>\n",
       "      <td>0.985665</td>\n",
       "      <td>0.020549</td>\n",
       "      <td>0.947392</td>\n",
       "      <td>1.004385</td>\n",
       "      <td>1.004385</td>\n",
       "      <td>0.121927</td>\n",
       "      <td>0.116296</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.383494</td>\n",
       "      <td>...</td>\n",
       "      <td>65.553615</td>\n",
       "      <td>180.477812</td>\n",
       "      <td>0.121604</td>\n",
       "      <td>665.090301</td>\n",
       "      <td>0.121604</td>\n",
       "      <td>5.038310</td>\n",
       "      <td>15.112799</td>\n",
       "      <td>0.094932</td>\n",
       "      <td>55.298213</td>\n",
       "      <td>0.100152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4572</th>\n",
       "      <td>ffd4ac1fe3746d586e00906a56ae8a26fdad358f5b4789...</td>\n",
       "      <td>0.583752</td>\n",
       "      <td>0.079215</td>\n",
       "      <td>0.441809</td>\n",
       "      <td>0.716586</td>\n",
       "      <td>0.537270</td>\n",
       "      <td>0.303983</td>\n",
       "      <td>0.264887</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.886130</td>\n",
       "      <td>...</td>\n",
       "      <td>4.226561</td>\n",
       "      <td>3.724987</td>\n",
       "      <td>0.151578</td>\n",
       "      <td>9.621307</td>\n",
       "      <td>1.134810</td>\n",
       "      <td>1.466304</td>\n",
       "      <td>2.095533</td>\n",
       "      <td>0.244888</td>\n",
       "      <td>8.276437</td>\n",
       "      <td>0.731602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4573</th>\n",
       "      <td>ffd6a301b0f94dec47dda9fec844cdc640a04bb38e8707...</td>\n",
       "      <td>0.371422</td>\n",
       "      <td>0.028512</td>\n",
       "      <td>0.332961</td>\n",
       "      <td>0.422435</td>\n",
       "      <td>0.375672</td>\n",
       "      <td>0.057875</td>\n",
       "      <td>0.083183</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0.243254</td>\n",
       "      <td>...</td>\n",
       "      <td>5.333977</td>\n",
       "      <td>17.184645</td>\n",
       "      <td>0.341976</td>\n",
       "      <td>62.526558</td>\n",
       "      <td>0.341976</td>\n",
       "      <td>0.085933</td>\n",
       "      <td>0.196977</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.538306</td>\n",
       "      <td>0.009001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4574</th>\n",
       "      <td>ffec525f2274773988a28374018c28326397b4b1dc1f6b...</td>\n",
       "      <td>0.897094</td>\n",
       "      <td>0.017155</td>\n",
       "      <td>0.864263</td>\n",
       "      <td>0.915203</td>\n",
       "      <td>0.915203</td>\n",
       "      <td>0.244309</td>\n",
       "      <td>0.170227</td>\n",
       "      <td>0.004161</td>\n",
       "      <td>0.419762</td>\n",
       "      <td>...</td>\n",
       "      <td>3.801205</td>\n",
       "      <td>4.393120</td>\n",
       "      <td>0.555406</td>\n",
       "      <td>13.938517</td>\n",
       "      <td>1.515954</td>\n",
       "      <td>2.156880</td>\n",
       "      <td>2.540913</td>\n",
       "      <td>0.033297</td>\n",
       "      <td>8.326040</td>\n",
       "      <td>0.588819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4575 rows × 951 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            customer_ID  P_2_mean   P_2_std  \\\n",
       "0     000919ba92d9a04c28e1e49f6cd855ca36e1df7c79cc05...  0.499402  0.015600   \n",
       "1     00158cf08fcf7ec058529dd71b4cff04ce89314e79840b...  0.691427  0.024675   \n",
       "2     0018753794d55ff4ab24aaa7f8e65d504fd1efbf04e369...  0.281522  0.090988   \n",
       "3     0044d8693a5c204d5e22297b11e566d9de1c1610899d20...  0.863033  0.035847   \n",
       "4     00597bc3d552264d841bd1a52cfaf3ebe40755f96d85a5...  0.343063  0.047509   \n",
       "...                                                 ...       ...       ...   \n",
       "4570  ffbdeb593c97bc39bf6228e7236796cf5dcd530ef73014...  0.800766  0.054486   \n",
       "4571  ffbff903bdd4104397101a428a4c5c4daa4d28e26f8716...  0.985665  0.020549   \n",
       "4572  ffd4ac1fe3746d586e00906a56ae8a26fdad358f5b4789...  0.583752  0.079215   \n",
       "4573  ffd6a301b0f94dec47dda9fec844cdc640a04bb38e8707...  0.371422  0.028512   \n",
       "4574  ffec525f2274773988a28374018c28326397b4b1dc1f6b...  0.897094  0.017155   \n",
       "\n",
       "       P_2_min   P_2_max  P_2_last  D_39_mean  D_39_std  D_39_min  D_39_max  \\\n",
       "0     0.476616  0.522344  0.498361   0.470466  0.198861  0.004601  0.830081   \n",
       "1     0.666900  0.733644  0.707521   0.026813  0.080476  0.000230  0.294493   \n",
       "2     0.198344  0.498234  0.325086   0.095091  0.185570  0.001569  0.567713   \n",
       "3     0.808965  0.915033  0.878732   0.005821  0.002665  0.001335  0.009564   \n",
       "4     0.220225  0.378734  0.371411   0.164823  0.201824  0.009121  0.803373   \n",
       "...        ...       ...       ...        ...       ...       ...       ...   \n",
       "4570  0.665637  0.855915  0.823051   0.551746  0.366059  0.004717  1.215695   \n",
       "4571  0.947392  1.004385  1.004385   0.121927  0.116296  0.000431  0.383494   \n",
       "4572  0.441809  0.716586  0.537270   0.303983  0.264887  0.001018  0.886130   \n",
       "4573  0.332961  0.422435  0.375672   0.057875  0.083183  0.005337  0.243254   \n",
       "4574  0.864263  0.915203  0.915203   0.244309  0.170227  0.004161  0.419762   \n",
       "\n",
       "      ...  c_PB_49_mean  c_PB_49_std  c_PB_49_min  c_PB_49_max  c_PB_49_last  \\\n",
       "0     ...    225.297543   213.187017    64.916394   696.014237    125.073946   \n",
       "1     ...      1.827795     3.524579     0.001253    11.108380      3.967306   \n",
       "2     ...    316.086714   580.285457     0.613235  2192.639080     30.993720   \n",
       "3     ...      0.895997     0.657292     0.160506     2.215508      2.215508   \n",
       "4     ...    298.391624   511.164682    59.923864  1947.667927    122.563743   \n",
       "...   ...           ...          ...          ...          ...           ...   \n",
       "4570  ...      1.925914     3.953065     0.031917    14.654292      0.839985   \n",
       "4571  ...     65.553615   180.477812     0.121604   665.090301      0.121604   \n",
       "4572  ...      4.226561     3.724987     0.151578     9.621307      1.134810   \n",
       "4573  ...      5.333977    17.184645     0.341976    62.526558      0.341976   \n",
       "4574  ...      3.801205     4.393120     0.555406    13.938517      1.515954   \n",
       "\n",
       "      c_PR_41_mean  c_PR_41_std  c_PR_41_min  c_PR_41_max  c_PR_41_last  \n",
       "0        10.058885    22.090925     0.001433    67.413339      0.259988  \n",
       "1         1.004138     1.743268     0.001401     4.546990      3.423076  \n",
       "2        24.989575    42.628358     0.006441   114.600555      0.949760  \n",
       "3         0.837358     0.695346     0.004019     2.406603      2.406603  \n",
       "4       127.859961   221.530941    27.114767   844.638848     54.379913  \n",
       "...            ...          ...          ...          ...           ...  \n",
       "4570      2.738269     4.365143     0.241016    14.539556      0.907417  \n",
       "4571      5.038310    15.112799     0.094932    55.298213      0.100152  \n",
       "4572      1.466304     2.095533     0.244888     8.276437      0.731602  \n",
       "4573      0.085933     0.196977     0.000415     0.538306      0.009001  \n",
       "4574      2.156880     2.540913     0.033297     8.326040      0.588819  \n",
       "\n",
       "[4575 rows x 951 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_num_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_difference(data, num_features):\n",
    "    df1 = []\n",
    "    customer_ids = []\n",
    "    for customer_id, df in tqdm(data.groupby(['customer_ID'])):\n",
    "        # Get the differences\n",
    "        diff_df1 = df[num_features].diff(1).iloc[[-1]].values.astype(np.float32)\n",
    "        # Append to lists\n",
    "        df1.append(diff_df1)\n",
    "        customer_ids.append(customer_id)\n",
    "    # Concatenate\n",
    "    df1 = np.concatenate(df1, axis = 0)\n",
    "    # Transform to dataframe\n",
    "    df1 = pd.DataFrame(df1, columns = [col + '_diff1' for col in df[num_features].columns])\n",
    "    # Add customer id\n",
    "    df1['customer_ID'] = customer_ids\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4575/4575 [00:15<00:00, 299.81it/s]\n"
     ]
    }
   ],
   "source": [
    "train_diff = get_difference(df, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## categorical feature aggregation\n",
    "train_cat_agg = df.groupby(\"customer_ID\")[cat_vars].agg(['count', 'last', 'nunique']) # give summary statistics for each categrocial feature\n",
    "train_cat_agg.columns = ['_'.join(x) for x in train_cat_agg.columns] # join the column name tuples to a single name\n",
    "train_cat_agg.reset_index(inplace = True) # get the customer_ID in as a column again and reset index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = train_num_agg.merge(train_cat_agg, how = 'inner', on = 'customer_ID').merge(train_diff, how = 'inner', on = 'customer_ID').merge(target, how = 'inner', on = 'customer_ID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>P_2_mean</th>\n",
       "      <th>P_2_std</th>\n",
       "      <th>P_2_min</th>\n",
       "      <th>P_2_max</th>\n",
       "      <th>P_2_last</th>\n",
       "      <th>D_39_mean</th>\n",
       "      <th>D_39_std</th>\n",
       "      <th>D_39_min</th>\n",
       "      <th>D_39_max</th>\n",
       "      <th>...</th>\n",
       "      <th>c_BBBB1_diff1</th>\n",
       "      <th>c_BBBB2_diff1</th>\n",
       "      <th>c_RRR0_diff1</th>\n",
       "      <th>c_RRR1_diff1</th>\n",
       "      <th>c_PD_348_diff1</th>\n",
       "      <th>c_PD_355_diff1</th>\n",
       "      <th>c_PD_439_diff1</th>\n",
       "      <th>c_PB_49_diff1</th>\n",
       "      <th>c_PR_41_diff1</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000919ba92d9a04c28e1e49f6cd855ca36e1df7c79cc05...</td>\n",
       "      <td>0.499402</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.476616</td>\n",
       "      <td>0.522344</td>\n",
       "      <td>0.498361</td>\n",
       "      <td>0.470466</td>\n",
       "      <td>0.198861</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.830081</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008202</td>\n",
       "      <td>-0.315132</td>\n",
       "      <td>-2.043217</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>-0.043284</td>\n",
       "      <td>-0.053059</td>\n",
       "      <td>-55.872944</td>\n",
       "      <td>-215.132233</td>\n",
       "      <td>-1.278214</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00158cf08fcf7ec058529dd71b4cff04ce89314e79840b...</td>\n",
       "      <td>0.691427</td>\n",
       "      <td>0.024675</td>\n",
       "      <td>0.666900</td>\n",
       "      <td>0.733644</td>\n",
       "      <td>0.707521</td>\n",
       "      <td>0.026813</td>\n",
       "      <td>0.080476</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.294493</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001197</td>\n",
       "      <td>-0.001025</td>\n",
       "      <td>1.261794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.105418</td>\n",
       "      <td>0.002994</td>\n",
       "      <td>-1.430107</td>\n",
       "      <td>-3.275841</td>\n",
       "      <td>-1.123914</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0018753794d55ff4ab24aaa7f8e65d504fd1efbf04e369...</td>\n",
       "      <td>0.281522</td>\n",
       "      <td>0.090988</td>\n",
       "      <td>0.198344</td>\n",
       "      <td>0.498234</td>\n",
       "      <td>0.325086</td>\n",
       "      <td>0.095091</td>\n",
       "      <td>0.185570</td>\n",
       "      <td>0.001569</td>\n",
       "      <td>0.567713</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.855067</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>-4.628440</td>\n",
       "      <td>-0.002885</td>\n",
       "      <td>0.123645</td>\n",
       "      <td>0.011405</td>\n",
       "      <td>-0.592819</td>\n",
       "      <td>-110.659798</td>\n",
       "      <td>-5.362189</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0044d8693a5c204d5e22297b11e566d9de1c1610899d20...</td>\n",
       "      <td>0.863033</td>\n",
       "      <td>0.035847</td>\n",
       "      <td>0.808965</td>\n",
       "      <td>0.915033</td>\n",
       "      <td>0.878732</td>\n",
       "      <td>0.005821</td>\n",
       "      <td>0.002665</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>0.009564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008055</td>\n",
       "      <td>0.036351</td>\n",
       "      <td>1.186878</td>\n",
       "      <td>-0.001879</td>\n",
       "      <td>-0.075793</td>\n",
       "      <td>-0.040460</td>\n",
       "      <td>-0.219735</td>\n",
       "      <td>1.817076</td>\n",
       "      <td>2.402584</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00597bc3d552264d841bd1a52cfaf3ebe40755f96d85a5...</td>\n",
       "      <td>0.343063</td>\n",
       "      <td>0.047509</td>\n",
       "      <td>0.220225</td>\n",
       "      <td>0.378734</td>\n",
       "      <td>0.371411</td>\n",
       "      <td>0.164823</td>\n",
       "      <td>0.201824</td>\n",
       "      <td>0.009121</td>\n",
       "      <td>0.803373</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.042807</td>\n",
       "      <td>0.118287</td>\n",
       "      <td>-0.080717</td>\n",
       "      <td>0.058666</td>\n",
       "      <td>0.057578</td>\n",
       "      <td>-76.647720</td>\n",
       "      <td>-194.107788</td>\n",
       "      <td>-83.419312</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4570</th>\n",
       "      <td>ffbdeb593c97bc39bf6228e7236796cf5dcd530ef73014...</td>\n",
       "      <td>0.800766</td>\n",
       "      <td>0.054486</td>\n",
       "      <td>0.665637</td>\n",
       "      <td>0.855915</td>\n",
       "      <td>0.823051</td>\n",
       "      <td>0.551746</td>\n",
       "      <td>0.366059</td>\n",
       "      <td>0.004717</td>\n",
       "      <td>1.215695</td>\n",
       "      <td>...</td>\n",
       "      <td>1.759626</td>\n",
       "      <td>0.187208</td>\n",
       "      <td>-0.001998</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.063895</td>\n",
       "      <td>0.040283</td>\n",
       "      <td>71.111038</td>\n",
       "      <td>0.162405</td>\n",
       "      <td>0.518457</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4571</th>\n",
       "      <td>ffbff903bdd4104397101a428a4c5c4daa4d28e26f8716...</td>\n",
       "      <td>0.985665</td>\n",
       "      <td>0.020549</td>\n",
       "      <td>0.947392</td>\n",
       "      <td>1.004385</td>\n",
       "      <td>1.004385</td>\n",
       "      <td>0.121927</td>\n",
       "      <td>0.116296</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.383494</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003195</td>\n",
       "      <td>-0.013913</td>\n",
       "      <td>0.512358</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>-0.218525</td>\n",
       "      <td>-0.020217</td>\n",
       "      <td>-5.684210</td>\n",
       "      <td>-17.958992</td>\n",
       "      <td>-0.272193</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4572</th>\n",
       "      <td>ffd4ac1fe3746d586e00906a56ae8a26fdad358f5b4789...</td>\n",
       "      <td>0.583752</td>\n",
       "      <td>0.079215</td>\n",
       "      <td>0.441809</td>\n",
       "      <td>0.716586</td>\n",
       "      <td>0.537270</td>\n",
       "      <td>0.303983</td>\n",
       "      <td>0.264887</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.886130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008777</td>\n",
       "      <td>0.007561</td>\n",
       "      <td>5.159636</td>\n",
       "      <td>0.001569</td>\n",
       "      <td>0.011175</td>\n",
       "      <td>0.085185</td>\n",
       "      <td>41.172752</td>\n",
       "      <td>0.528886</td>\n",
       "      <td>-0.146537</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4573</th>\n",
       "      <td>ffd6a301b0f94dec47dda9fec844cdc640a04bb38e8707...</td>\n",
       "      <td>0.371422</td>\n",
       "      <td>0.028512</td>\n",
       "      <td>0.332961</td>\n",
       "      <td>0.422435</td>\n",
       "      <td>0.375672</td>\n",
       "      <td>0.057875</td>\n",
       "      <td>0.083183</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0.243254</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.823282</td>\n",
       "      <td>-1.243660</td>\n",
       "      <td>26.029510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.033933</td>\n",
       "      <td>-62.184582</td>\n",
       "      <td>-0.529305</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4574</th>\n",
       "      <td>ffec525f2274773988a28374018c28326397b4b1dc1f6b...</td>\n",
       "      <td>0.897094</td>\n",
       "      <td>0.017155</td>\n",
       "      <td>0.864263</td>\n",
       "      <td>0.915203</td>\n",
       "      <td>0.915203</td>\n",
       "      <td>0.244309</td>\n",
       "      <td>0.170227</td>\n",
       "      <td>0.004161</td>\n",
       "      <td>0.419762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004889</td>\n",
       "      <td>-0.007439</td>\n",
       "      <td>-0.007446</td>\n",
       "      <td>-0.000948</td>\n",
       "      <td>-0.056156</td>\n",
       "      <td>-0.049650</td>\n",
       "      <td>-104.025948</td>\n",
       "      <td>-0.077816</td>\n",
       "      <td>0.536353</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4575 rows × 1175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            customer_ID  P_2_mean   P_2_std  \\\n",
       "0     000919ba92d9a04c28e1e49f6cd855ca36e1df7c79cc05...  0.499402  0.015600   \n",
       "1     00158cf08fcf7ec058529dd71b4cff04ce89314e79840b...  0.691427  0.024675   \n",
       "2     0018753794d55ff4ab24aaa7f8e65d504fd1efbf04e369...  0.281522  0.090988   \n",
       "3     0044d8693a5c204d5e22297b11e566d9de1c1610899d20...  0.863033  0.035847   \n",
       "4     00597bc3d552264d841bd1a52cfaf3ebe40755f96d85a5...  0.343063  0.047509   \n",
       "...                                                 ...       ...       ...   \n",
       "4570  ffbdeb593c97bc39bf6228e7236796cf5dcd530ef73014...  0.800766  0.054486   \n",
       "4571  ffbff903bdd4104397101a428a4c5c4daa4d28e26f8716...  0.985665  0.020549   \n",
       "4572  ffd4ac1fe3746d586e00906a56ae8a26fdad358f5b4789...  0.583752  0.079215   \n",
       "4573  ffd6a301b0f94dec47dda9fec844cdc640a04bb38e8707...  0.371422  0.028512   \n",
       "4574  ffec525f2274773988a28374018c28326397b4b1dc1f6b...  0.897094  0.017155   \n",
       "\n",
       "       P_2_min   P_2_max  P_2_last  D_39_mean  D_39_std  D_39_min  D_39_max  \\\n",
       "0     0.476616  0.522344  0.498361   0.470466  0.198861  0.004601  0.830081   \n",
       "1     0.666900  0.733644  0.707521   0.026813  0.080476  0.000230  0.294493   \n",
       "2     0.198344  0.498234  0.325086   0.095091  0.185570  0.001569  0.567713   \n",
       "3     0.808965  0.915033  0.878732   0.005821  0.002665  0.001335  0.009564   \n",
       "4     0.220225  0.378734  0.371411   0.164823  0.201824  0.009121  0.803373   \n",
       "...        ...       ...       ...        ...       ...       ...       ...   \n",
       "4570  0.665637  0.855915  0.823051   0.551746  0.366059  0.004717  1.215695   \n",
       "4571  0.947392  1.004385  1.004385   0.121927  0.116296  0.000431  0.383494   \n",
       "4572  0.441809  0.716586  0.537270   0.303983  0.264887  0.001018  0.886130   \n",
       "4573  0.332961  0.422435  0.375672   0.057875  0.083183  0.005337  0.243254   \n",
       "4574  0.864263  0.915203  0.915203   0.244309  0.170227  0.004161  0.419762   \n",
       "\n",
       "      ...  c_BBBB1_diff1  c_BBBB2_diff1  c_RRR0_diff1  c_RRR1_diff1  \\\n",
       "0     ...      -0.008202      -0.315132     -2.043217      0.000802   \n",
       "1     ...      -0.001197      -0.001025      1.261794           NaN   \n",
       "2     ...      -0.855067       0.000209     -4.628440     -0.002885   \n",
       "3     ...       0.008055       0.036351      1.186878     -0.001879   \n",
       "4     ...            NaN       0.042807      0.118287     -0.080717   \n",
       "...   ...            ...            ...           ...           ...   \n",
       "4570  ...       1.759626       0.187208     -0.001998      0.005859   \n",
       "4571  ...      -0.003195      -0.013913      0.512358      0.000810   \n",
       "4572  ...       0.008777       0.007561      5.159636      0.001569   \n",
       "4573  ...      -1.823282      -1.243660     26.029510           NaN   \n",
       "4574  ...       0.004889      -0.007439     -0.007446     -0.000948   \n",
       "\n",
       "      c_PD_348_diff1  c_PD_355_diff1  c_PD_439_diff1  c_PB_49_diff1  \\\n",
       "0          -0.043284       -0.053059      -55.872944    -215.132233   \n",
       "1           0.105418        0.002994       -1.430107      -3.275841   \n",
       "2           0.123645        0.011405       -0.592819    -110.659798   \n",
       "3          -0.075793       -0.040460       -0.219735       1.817076   \n",
       "4           0.058666        0.057578      -76.647720    -194.107788   \n",
       "...              ...             ...             ...            ...   \n",
       "4570        0.063895        0.040283       71.111038       0.162405   \n",
       "4571       -0.218525       -0.020217       -5.684210     -17.958992   \n",
       "4572        0.011175        0.085185       41.172752       0.528886   \n",
       "4573             NaN             NaN       -1.033933     -62.184582   \n",
       "4574       -0.056156       -0.049650     -104.025948      -0.077816   \n",
       "\n",
       "      c_PR_41_diff1  target  \n",
       "0         -1.278214       0  \n",
       "1         -1.123914       0  \n",
       "2         -5.362189       1  \n",
       "3          2.402584       0  \n",
       "4        -83.419312       1  \n",
       "...             ...     ...  \n",
       "4570       0.518457       0  \n",
       "4571      -0.272193       0  \n",
       "4572      -0.146537       0  \n",
       "4573      -0.529305       1  \n",
       "4574       0.536353       0  \n",
       "\n",
       "[4575 rows x 1175 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "del train_num_agg, train_cat_agg, train_diff\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [f\"{cf}_last\" for cf in cat_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg[cat_features] = encoder.fit_transform(df_agg[cat_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols_mean = [col for col in df_agg.columns if 'mean' in col]\n",
    "num_cols_last = [col for col in df_agg.columns if 'last' in col and col not in cat_features]\n",
    "\n",
    "\n",
    "for col in range(len(num_cols_last)):\n",
    "    try:\n",
    "        df_agg[f'{num_cols_last[col]}_mean_diff'] = df_agg[num_cols_last[col]] - df_agg[num_cols_mean[col]]\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>P_2_mean</th>\n",
       "      <th>P_2_std</th>\n",
       "      <th>P_2_min</th>\n",
       "      <th>P_2_max</th>\n",
       "      <th>P_2_last</th>\n",
       "      <th>D_39_mean</th>\n",
       "      <th>D_39_std</th>\n",
       "      <th>D_39_min</th>\n",
       "      <th>D_39_max</th>\n",
       "      <th>...</th>\n",
       "      <th>c_BBBB_last_mean_diff</th>\n",
       "      <th>c_BBBB1_last_mean_diff</th>\n",
       "      <th>c_BBBB2_last_mean_diff</th>\n",
       "      <th>c_RRR0_last_mean_diff</th>\n",
       "      <th>c_RRR1_last_mean_diff</th>\n",
       "      <th>c_PD_348_last_mean_diff</th>\n",
       "      <th>c_PD_355_last_mean_diff</th>\n",
       "      <th>c_PD_439_last_mean_diff</th>\n",
       "      <th>c_PB_49_last_mean_diff</th>\n",
       "      <th>c_PR_41_last_mean_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000919ba92d9a04c28e1e49f6cd855ca36e1df7c79cc05...</td>\n",
       "      <td>0.499402</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.476616</td>\n",
       "      <td>0.522344</td>\n",
       "      <td>0.498361</td>\n",
       "      <td>0.470466</td>\n",
       "      <td>0.198861</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.830081</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019302</td>\n",
       "      <td>0.083203</td>\n",
       "      <td>-0.179792</td>\n",
       "      <td>-0.031441</td>\n",
       "      <td>0.002298</td>\n",
       "      <td>-0.051647</td>\n",
       "      <td>-0.046471</td>\n",
       "      <td>-32.842237</td>\n",
       "      <td>-100.223597</td>\n",
       "      <td>-9.798897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00158cf08fcf7ec058529dd71b4cff04ce89314e79840b...</td>\n",
       "      <td>0.691427</td>\n",
       "      <td>0.024675</td>\n",
       "      <td>0.666900</td>\n",
       "      <td>0.733644</td>\n",
       "      <td>0.707521</td>\n",
       "      <td>0.026813</td>\n",
       "      <td>0.080476</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.294493</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.868411</td>\n",
       "      <td>-0.077614</td>\n",
       "      <td>-0.011059</td>\n",
       "      <td>-10.544500</td>\n",
       "      <td>0.039070</td>\n",
       "      <td>-0.004932</td>\n",
       "      <td>0.028528</td>\n",
       "      <td>0.998090</td>\n",
       "      <td>2.139511</td>\n",
       "      <td>2.418938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0018753794d55ff4ab24aaa7f8e65d504fd1efbf04e369...</td>\n",
       "      <td>0.281522</td>\n",
       "      <td>0.090988</td>\n",
       "      <td>0.198344</td>\n",
       "      <td>0.498234</td>\n",
       "      <td>0.325086</td>\n",
       "      <td>0.095091</td>\n",
       "      <td>0.185570</td>\n",
       "      <td>0.001569</td>\n",
       "      <td>0.567713</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.508805</td>\n",
       "      <td>-1.227995</td>\n",
       "      <td>-0.604594</td>\n",
       "      <td>15.042042</td>\n",
       "      <td>-0.001188</td>\n",
       "      <td>-0.531127</td>\n",
       "      <td>-0.288131</td>\n",
       "      <td>-64.127581</td>\n",
       "      <td>-285.092994</td>\n",
       "      <td>-24.039815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0044d8693a5c204d5e22297b11e566d9de1c1610899d20...</td>\n",
       "      <td>0.863033</td>\n",
       "      <td>0.035847</td>\n",
       "      <td>0.808965</td>\n",
       "      <td>0.915033</td>\n",
       "      <td>0.878732</td>\n",
       "      <td>0.005821</td>\n",
       "      <td>0.002665</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>0.009564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018584</td>\n",
       "      <td>0.010627</td>\n",
       "      <td>0.007818</td>\n",
       "      <td>10.131473</td>\n",
       "      <td>-0.013267</td>\n",
       "      <td>-0.008269</td>\n",
       "      <td>0.124844</td>\n",
       "      <td>0.455170</td>\n",
       "      <td>1.319511</td>\n",
       "      <td>1.569245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00597bc3d552264d841bd1a52cfaf3ebe40755f96d85a5...</td>\n",
       "      <td>0.343063</td>\n",
       "      <td>0.047509</td>\n",
       "      <td>0.220225</td>\n",
       "      <td>0.378734</td>\n",
       "      <td>0.371411</td>\n",
       "      <td>0.164823</td>\n",
       "      <td>0.201824</td>\n",
       "      <td>0.009121</td>\n",
       "      <td>0.803373</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024287</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>-0.040757</td>\n",
       "      <td>-0.417466</td>\n",
       "      <td>-0.074078</td>\n",
       "      <td>0.166081</td>\n",
       "      <td>0.198613</td>\n",
       "      <td>-21.583628</td>\n",
       "      <td>-175.827881</td>\n",
       "      <td>-73.480048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4570</th>\n",
       "      <td>ffbdeb593c97bc39bf6228e7236796cf5dcd530ef73014...</td>\n",
       "      <td>0.800766</td>\n",
       "      <td>0.054486</td>\n",
       "      <td>0.665637</td>\n",
       "      <td>0.855915</td>\n",
       "      <td>0.823051</td>\n",
       "      <td>0.551746</td>\n",
       "      <td>0.366059</td>\n",
       "      <td>0.004717</td>\n",
       "      <td>1.215695</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016377</td>\n",
       "      <td>0.968971</td>\n",
       "      <td>0.156534</td>\n",
       "      <td>-5.786874</td>\n",
       "      <td>0.005488</td>\n",
       "      <td>-0.169338</td>\n",
       "      <td>-0.105161</td>\n",
       "      <td>-137.114383</td>\n",
       "      <td>-1.085928</td>\n",
       "      <td>-1.830852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4571</th>\n",
       "      <td>ffbff903bdd4104397101a428a4c5c4daa4d28e26f8716...</td>\n",
       "      <td>0.985665</td>\n",
       "      <td>0.020549</td>\n",
       "      <td>0.947392</td>\n",
       "      <td>1.004385</td>\n",
       "      <td>1.004385</td>\n",
       "      <td>0.121927</td>\n",
       "      <td>0.116296</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.383494</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.032281</td>\n",
       "      <td>-0.027999</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>0.016325</td>\n",
       "      <td>0.003114</td>\n",
       "      <td>-0.080864</td>\n",
       "      <td>-0.000624</td>\n",
       "      <td>-86.080570</td>\n",
       "      <td>-65.432011</td>\n",
       "      <td>-4.938158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4572</th>\n",
       "      <td>ffd4ac1fe3746d586e00906a56ae8a26fdad358f5b4789...</td>\n",
       "      <td>0.583752</td>\n",
       "      <td>0.079215</td>\n",
       "      <td>0.441809</td>\n",
       "      <td>0.716586</td>\n",
       "      <td>0.537270</td>\n",
       "      <td>0.303983</td>\n",
       "      <td>0.264887</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.886130</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.174720</td>\n",
       "      <td>-0.055725</td>\n",
       "      <td>-0.003719</td>\n",
       "      <td>3.505672</td>\n",
       "      <td>-0.132084</td>\n",
       "      <td>0.729498</td>\n",
       "      <td>-0.100039</td>\n",
       "      <td>27.630789</td>\n",
       "      <td>-3.091750</td>\n",
       "      <td>-0.734702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4573</th>\n",
       "      <td>ffd6a301b0f94dec47dda9fec844cdc640a04bb38e8707...</td>\n",
       "      <td>0.371422</td>\n",
       "      <td>0.028512</td>\n",
       "      <td>0.332961</td>\n",
       "      <td>0.422435</td>\n",
       "      <td>0.375672</td>\n",
       "      <td>0.057875</td>\n",
       "      <td>0.083183</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0.243254</td>\n",
       "      <td>...</td>\n",
       "      <td>2.182336</td>\n",
       "      <td>-1.354337</td>\n",
       "      <td>-0.807737</td>\n",
       "      <td>19.895425</td>\n",
       "      <td>-0.000386</td>\n",
       "      <td>0.416058</td>\n",
       "      <td>0.365047</td>\n",
       "      <td>-0.133332</td>\n",
       "      <td>-4.992001</td>\n",
       "      <td>-0.076932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4574</th>\n",
       "      <td>ffec525f2274773988a28374018c28326397b4b1dc1f6b...</td>\n",
       "      <td>0.897094</td>\n",
       "      <td>0.017155</td>\n",
       "      <td>0.864263</td>\n",
       "      <td>0.915203</td>\n",
       "      <td>0.915203</td>\n",
       "      <td>0.244309</td>\n",
       "      <td>0.170227</td>\n",
       "      <td>0.004161</td>\n",
       "      <td>0.419762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.603116</td>\n",
       "      <td>-0.102233</td>\n",
       "      <td>-0.005822</td>\n",
       "      <td>-2.896174</td>\n",
       "      <td>0.067972</td>\n",
       "      <td>0.071775</td>\n",
       "      <td>-0.013733</td>\n",
       "      <td>-159.174482</td>\n",
       "      <td>-2.285251</td>\n",
       "      <td>-1.568061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4575 rows × 1365 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            customer_ID  P_2_mean   P_2_std  \\\n",
       "0     000919ba92d9a04c28e1e49f6cd855ca36e1df7c79cc05...  0.499402  0.015600   \n",
       "1     00158cf08fcf7ec058529dd71b4cff04ce89314e79840b...  0.691427  0.024675   \n",
       "2     0018753794d55ff4ab24aaa7f8e65d504fd1efbf04e369...  0.281522  0.090988   \n",
       "3     0044d8693a5c204d5e22297b11e566d9de1c1610899d20...  0.863033  0.035847   \n",
       "4     00597bc3d552264d841bd1a52cfaf3ebe40755f96d85a5...  0.343063  0.047509   \n",
       "...                                                 ...       ...       ...   \n",
       "4570  ffbdeb593c97bc39bf6228e7236796cf5dcd530ef73014...  0.800766  0.054486   \n",
       "4571  ffbff903bdd4104397101a428a4c5c4daa4d28e26f8716...  0.985665  0.020549   \n",
       "4572  ffd4ac1fe3746d586e00906a56ae8a26fdad358f5b4789...  0.583752  0.079215   \n",
       "4573  ffd6a301b0f94dec47dda9fec844cdc640a04bb38e8707...  0.371422  0.028512   \n",
       "4574  ffec525f2274773988a28374018c28326397b4b1dc1f6b...  0.897094  0.017155   \n",
       "\n",
       "       P_2_min   P_2_max  P_2_last  D_39_mean  D_39_std  D_39_min  D_39_max  \\\n",
       "0     0.476616  0.522344  0.498361   0.470466  0.198861  0.004601  0.830081   \n",
       "1     0.666900  0.733644  0.707521   0.026813  0.080476  0.000230  0.294493   \n",
       "2     0.198344  0.498234  0.325086   0.095091  0.185570  0.001569  0.567713   \n",
       "3     0.808965  0.915033  0.878732   0.005821  0.002665  0.001335  0.009564   \n",
       "4     0.220225  0.378734  0.371411   0.164823  0.201824  0.009121  0.803373   \n",
       "...        ...       ...       ...        ...       ...       ...       ...   \n",
       "4570  0.665637  0.855915  0.823051   0.551746  0.366059  0.004717  1.215695   \n",
       "4571  0.947392  1.004385  1.004385   0.121927  0.116296  0.000431  0.383494   \n",
       "4572  0.441809  0.716586  0.537270   0.303983  0.264887  0.001018  0.886130   \n",
       "4573  0.332961  0.422435  0.375672   0.057875  0.083183  0.005337  0.243254   \n",
       "4574  0.864263  0.915203  0.915203   0.244309  0.170227  0.004161  0.419762   \n",
       "\n",
       "      ...  c_BBBB_last_mean_diff  c_BBBB1_last_mean_diff  \\\n",
       "0     ...              -0.019302                0.083203   \n",
       "1     ...              -0.868411               -0.077614   \n",
       "2     ...              -0.508805               -1.227995   \n",
       "3     ...               0.018584                0.010627   \n",
       "4     ...              -0.024287                0.002214   \n",
       "...   ...                    ...                     ...   \n",
       "4570  ...              -0.016377                0.968971   \n",
       "4571  ...              -3.032281               -0.027999   \n",
       "4572  ...              -0.174720               -0.055725   \n",
       "4573  ...               2.182336               -1.354337   \n",
       "4574  ...               0.603116               -0.102233   \n",
       "\n",
       "      c_BBBB2_last_mean_diff  c_RRR0_last_mean_diff  c_RRR1_last_mean_diff  \\\n",
       "0                  -0.179792              -0.031441               0.002298   \n",
       "1                  -0.011059             -10.544500               0.039070   \n",
       "2                  -0.604594              15.042042              -0.001188   \n",
       "3                   0.007818              10.131473              -0.013267   \n",
       "4                  -0.040757              -0.417466              -0.074078   \n",
       "...                      ...                    ...                    ...   \n",
       "4570                0.156534              -5.786874               0.005488   \n",
       "4571                0.001957               0.016325               0.003114   \n",
       "4572               -0.003719               3.505672              -0.132084   \n",
       "4573               -0.807737              19.895425              -0.000386   \n",
       "4574               -0.005822              -2.896174               0.067972   \n",
       "\n",
       "      c_PD_348_last_mean_diff  c_PD_355_last_mean_diff  \\\n",
       "0                   -0.051647                -0.046471   \n",
       "1                   -0.004932                 0.028528   \n",
       "2                   -0.531127                -0.288131   \n",
       "3                   -0.008269                 0.124844   \n",
       "4                    0.166081                 0.198613   \n",
       "...                       ...                      ...   \n",
       "4570                -0.169338                -0.105161   \n",
       "4571                -0.080864                -0.000624   \n",
       "4572                 0.729498                -0.100039   \n",
       "4573                 0.416058                 0.365047   \n",
       "4574                 0.071775                -0.013733   \n",
       "\n",
       "      c_PD_439_last_mean_diff  c_PB_49_last_mean_diff  c_PR_41_last_mean_diff  \n",
       "0                  -32.842237             -100.223597               -9.798897  \n",
       "1                    0.998090                2.139511                2.418938  \n",
       "2                  -64.127581             -285.092994              -24.039815  \n",
       "3                    0.455170                1.319511                1.569245  \n",
       "4                  -21.583628             -175.827881              -73.480048  \n",
       "...                       ...                     ...                     ...  \n",
       "4570              -137.114383               -1.085928               -1.830852  \n",
       "4571               -86.080570              -65.432011               -4.938158  \n",
       "4572                27.630789               -3.091750               -0.734702  \n",
       "4573                -0.133332               -4.992001               -0.076932  \n",
       "4574              -159.174482               -2.285251               -1.568061  \n",
       "\n",
       "[4575 rows x 1365 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amex_metric(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "\n",
    "    ## TWEAK\n",
    "    y_pred = pd.Series(y_pred, index=y_true.index)\n",
    "\n",
    "    y_true = pd.DataFrame(y_true)\n",
    "    y_pred = pd.DataFrame(y_pred)\n",
    "\n",
    "    y_true = y_true.rename(columns={y_true.columns[0]:'target'})\n",
    "    y_pred = y_pred.rename(columns={y_pred.columns[0]:'prediction'})\n",
    "    ##\n",
    "\n",
    "    def top_four_percent_captured(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        four_pct_cutoff = int(0.04 * df['weight'].sum())\n",
    "        df['weight_cumsum'] = df['weight'].cumsum()\n",
    "        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n",
    "    def weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n",
    "        total_pos = (df['target'] * df['weight']).sum()\n",
    "        df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n",
    "        df['lorentz'] = df['cum_pos_found'] / total_pos\n",
    "        df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n",
    "        return df['gini'].sum()\n",
    "\n",
    "    def normalized_weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        y_true_pred = y_true.rename(columns={'target': 'prediction'})\n",
    "        return weighted_gini(y_true, y_pred) / weighted_gini(y_true, y_true_pred)\n",
    "\n",
    "    g = normalized_weighted_gini(y_true, y_pred)\n",
    "    d = top_four_percent_captured(y_true, y_pred)\n",
    "\n",
    "    return 0.5 * (g + d)\n",
    "\n",
    "def build_param_dict(boosting_type='gbdt', # params can be found here https://lightgbm.readthedocs.io/en/v3.3.2/Parameters.html\n",
    "                     max_depth=-1,\n",
    "                     n_estimators=100,\n",
    "                     num_leaves=31,\n",
    "                     class_weight = None, # might want to try is_unbalance\n",
    "                     learning_rate= 0.1,\n",
    "                     min_data_in_leaf=20,\n",
    "                     bagging_fraction=1.0,\n",
    "                     feature_fraction=1.0,\n",
    "                     objective='binary',\n",
    "                     reg_alpha=0.,\n",
    "                     reg_lambda=0.,\n",
    "                     categorical_features=cat_features,\n",
    "                     random_state=None, \n",
    "                     **kwargs\n",
    "                     ):\n",
    "\n",
    "    return dict(\n",
    "        boosting_type=boosting_type, # params can be found here https://lightgbm.readthedocs.io/en/v3.3.2/Parameters.html\n",
    "        max_depth=max_depth,\n",
    "        n_estimators=n_estimators,\n",
    "        num_leaves=num_leaves,\n",
    "        class_weight = class_weight, # might want to try is_unbalance\n",
    "        learning_rate= learning_rate,\n",
    "        min_data_in_leaf=min_data_in_leaf,\n",
    "        bagging_fraction=bagging_fraction,\n",
    "        feature_fraction=feature_fraction,\n",
    "        objective=objective,\n",
    "        reg_alpha=reg_alpha,\n",
    "        reg_lambda=reg_lambda,\n",
    "        categorical_feature=categorical_features,\n",
    "        random_state=random_state,\n",
    "        **kwargs\n",
    "        )\n",
    "\n",
    "\n",
    "def initialize_model(param_dict=build_param_dict()):\n",
    "\n",
    "    return lgb.LGBMClassifier(**param_dict)\n",
    "\n",
    "def train_model(model,\n",
    "                X: np.ndarray,\n",
    "                y: np.ndarray,\n",
    "                eval_metric=make_scorer(amex_metric),\n",
    "                early_stopping=30,\n",
    "                num_splits=1,\n",
    "                test_size = 0.3,\n",
    "                init_model = None, #(str, pathlib.Path, Booster, LGBMModel or None, optional (default=None)) – Filename of LightGBM model, Booster instance or LGBMModel instance used for continue training.\n",
    "                ):\n",
    "\n",
    "    ## make sure the passed data is aggregated, otherwise it is going to split row/wise, not ustomer wise\n",
    "\n",
    "    # check out init score and init model\n",
    "\n",
    "\n",
    "    eval_sets = []\n",
    "\n",
    "    for i in range(num_splits):\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_size)\n",
    "        eval_sets.append((X_val, y_val))\n",
    "\n",
    "    model.fit(X, y, early_stopping_rounds=early_stopping, eval_metric=eval_metric, eval_set=eval_sets, init_model=None)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Configurations\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    seed = 42\n",
    "    n_folds = 5\n",
    "    target = 'target'\n",
    "    boosting_type = 'dart'\n",
    "    metric = 'binary_logloss'\n",
    "\n",
    "# ====================================================\n",
    "# Seed everything\n",
    "# ====================================================\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_agg.drop(columns=['customer_ID', 'target'])\n",
    "y = df_agg['target']\n",
    "X_train, X_val, y_train1, y_val1 = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': CFG.metric,\n",
    "    'boosting': CFG.boosting_type,\n",
    "    'seed': CFG.seed,\n",
    "    'num_leaves': 100,\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 0.20,\n",
    "    'bagging_freq': 10,\n",
    "    'bagging_fraction': 0.50,\n",
    "    'n_jobs': -1,\n",
    "    'lambda_l2': 2,\n",
    "    'min_data_in_leaf': 40,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Amex metric\n",
    "# ====================================================\n",
    "def amex_metric(y_true, y_pred):\n",
    "    labels = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz = cum_pos_found / total_pos\n",
    "        gini[i] = np.sum((lorentz - weight_random) * weight)\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
    "\n",
    "# ====================================================\n",
    "# LGBM amex metric\n",
    "# ====================================================\n",
    "def lgb_amex_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return 'amex_metric', amex_metric(y_true, y_pred), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a numpy array to store test predictions\n",
    "test_predictions = np.zeros(len(X_train))\n",
    "# Create a numpy array to store out of folds predictions\n",
    "oof_predictions = np.zeros(len(X_train))\n",
    "kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n",
    "\n",
    "features = X_train.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  16   18   24   30   33   36   48   50   53   54   58   66   68   74\n",
      "   77   83   85   89   92   95   96  101  102  103  108  113  116  122\n",
      "  131  136  171  174  177  184  185  191  195  201  206  209  212  216\n",
      "  218  234  237  254  258  259  263  272  274  281  286  290  294  295\n",
      "  299  305  306  311  320  336  338  340  346  353  355  357  359  361\n",
      "  368  369  371  372  376  379  383  394  399  402  412  415  421  422\n",
      "  423  431  438  441  445  450  465  466  472  477  478  479  481  482\n",
      "  487  495  501  503  517  519  526  530  537  539  545  552  553  554\n",
      "  555  556  560  565  572  573  577  581  585  589  592  595  596  601\n",
      "  611  615  619  620  624  628  629  633  634  636  649  650  656  662\n",
      "  663  664  665  671  675  678  679  683  690  693  697  704  714  715\n",
      "  721  747  749  753  757  761  764  766  772  773  780  782  784  788\n",
      "  789  790  792  794  800  806  825  831  836  838  849  850  857  858\n",
      "  861  863  864  870  871  877  885  889  891  892  896  898  909  917\n",
      "  918  922  924  925  926  932  935  945  953  962  964  967  971  973\n",
      "  986  989  993  996 1005 1008 1012 1021 1031 1039 1040 1042 1045 1050\n",
      " 1057 1058 1063 1064 1065 1085 1091 1093 1103 1110 1115 1117 1118 1121\n",
      " 1123 1124 1126 1127 1129 1137 1151 1153 1156 1161 1171 1178 1179 1182\n",
      " 1184 1187 1188 1190 1194 1204 1206 1207 1209 1214 1222 1230 1234 1238\n",
      " 1239 1246 1253 1254 1255 1258 1263 1265 1267 1273 1276 1283 1285 1297\n",
      " 1301 1303 1306 1310 1314 1319 1321 1322 1328 1335 1336 1338 1351 1355\n",
      " 1360 1365 1368 1379 1388 1393 1404 1412 1426 1427 1430 1437 1440 1449\n",
      " 1452 1455 1457 1459 1470 1473 1483 1485 1495 1515 1519 1520 1525 1526\n",
      " 1530 1534 1537 1538 1541 1543 1549 1552 1554 1557 1561 1568 1571 1573\n",
      " 1579 1589 1599 1602 1603 1616 1624 1633 1637 1639 1642 1653 1655 1658\n",
      " 1666 1668 1680 1685 1697 1700 1703 1707 1709 1722 1730 1731 1733 1734\n",
      " 1738 1743 1756 1779 1785 1786 1793 1795 1796 1807 1808 1810 1811 1812\n",
      " 1816 1823 1836 1838 1846 1847 1848 1854 1860 1863 1875 1878 1879 1885\n",
      " 1886 1891 1892 1895 1900 1902 1905 1912 1936 1938 1940 1944 1946 1948\n",
      " 1952 1957 1963 1967 1982 1989 1994 2005 2006 2007 2014 2022 2026 2033\n",
      " 2035 2041 2043 2054 2057 2065 2067 2070 2080 2093 2094 2099 2105 2106\n",
      " 2107 2110 2116 2124 2140 2141 2161 2164 2167 2169 2170 2173 2179 2181\n",
      " 2185 2188 2198 2199 2202 2208 2222 2229 2234 2236 2238 2244 2247 2264\n",
      " 2267 2275 2286 2294 2298 2301 2305 2308 2312 2317 2322 2327 2334 2338\n",
      " 2352 2355 2356 2357 2361 2363 2369 2374 2377 2380 2381 2382 2384 2385\n",
      " 2390 2394 2405 2407 2409 2428 2431 2435 2440 2444 2446 2452 2455 2457\n",
      " 2458 2460 2463 2469 2471 2473 2475 2477 2479 2485 2493 2494 2497 2499\n",
      " 2504 2511 2513 2514 2522 2534 2537 2540 2544 2545 2547 2552 2554 2558\n",
      " 2565 2566 2568 2573 2577 2578 2580 2591 2593 2595 2596 2599 2600 2609\n",
      " 2615 2617 2618 2621 2636 2637 2641 2645 2650 2651 2656 2664 2673 2688\n",
      " 2692 2704 2714 2719 2720 2723 2733 2743 2755 2756 2757 2767 2770 2782\n",
      " 2785 2791 2797 2798 2801 2823 2838 2845 2847 2848 2851 2862 2863 2874\n",
      " 2879 2880 2883 2889 2890 2908 2910 2920 2939 2949 2955 2964 2974 2981\n",
      " 2982 2983 2984 2990 2992 3004 3013 3014 3016 3027 3030 3041 3046 3053\n",
      " 3054 3063 3064 3073 3076 3087 3088 3098 3099 3101 3108 3114 3120 3122\n",
      " 3123 3133 3140 3141 3143 3157 3162 3169 3171 3175 3184 3188 3192 3194\n",
      " 3196 3197 3198 3199 3209 3214 3220 3236 3245 3254 3274 3277 3284 3285\n",
      " 3287 3299 3301 3304 3309 3311 3313 3320 3323 3324 3333 3337 3342 3343\n",
      " 3357 3367 3369 3378 3385 3387 3393 3396 3398 3410 3414 3417 3419 3421\n",
      " 3423]\n",
      "[   0    4    5   12   13   21   26   57   61   70   71   73   76   80\n",
      "   84   86  106  111  112  119  123  124  128  129  130  138  140  142\n",
      "  144  157  161  163  168  173  179  180  181  188  197  200  202  205\n",
      "  208  215  225  229  230  233  239  241  244  246  255  262  265  266\n",
      "  267  271  282  285  288  289  292  296  304  308  312  314  321  323\n",
      "  332  344  350  363  367  374  385  387  388  401  410  420  424  425\n",
      "  428  433  448  452  459  462  469  470  484  492  494  497  500  502\n",
      "  512  513  514  529  534  535  542  547  549  550  558  562  563  568\n",
      "  576  584  593  594  602  604  606  616  626  641  643  652  655  666\n",
      "  668  673  674  682  684  688  694  695  700  710  712  713  718  723\n",
      "  728  730  732  734  737  741  750  752  754  760  763  778  791  797\n",
      "  803  810  813  814  819  820  826  828  834  837  840  842  845  847\n",
      "  867  869  872  874  876  878  881  883  886  890  902  906  911  912\n",
      "  927  938  939  940  944  946  949  950  951  956  961  970  974  982\n",
      "  985  987  994  997  998  999 1001 1006 1014 1017 1028 1030 1049 1055\n",
      " 1059 1066 1068 1069 1076 1078 1080 1090 1095 1100 1107 1112 1125 1139\n",
      " 1140 1144 1146 1150 1152 1159 1162 1169 1174 1183 1197 1208 1212 1217\n",
      " 1220 1221 1224 1225 1227 1228 1231 1235 1241 1244 1245 1249 1251 1270\n",
      " 1271 1278 1284 1305 1312 1327 1331 1332 1337 1340 1344 1357 1358 1361\n",
      " 1363 1371 1373 1374 1378 1381 1384 1385 1386 1387 1394 1396 1402 1405\n",
      " 1420 1425 1447 1450 1453 1463 1466 1468 1469 1474 1479 1488 1491 1501\n",
      " 1509 1513 1516 1517 1518 1523 1527 1533 1539 1545 1558 1562 1564 1574\n",
      " 1580 1581 1585 1587 1588 1590 1592 1593 1595 1596 1598 1601 1609 1615\n",
      " 1621 1631 1636 1640 1648 1649 1654 1667 1669 1676 1677 1688 1689 1693\n",
      " 1695 1696 1704 1708 1713 1728 1736 1744 1745 1749 1753 1757 1760 1762\n",
      " 1766 1769 1778 1780 1781 1782 1790 1794 1797 1799 1802 1804 1805 1809\n",
      " 1841 1850 1852 1862 1865 1868 1871 1872 1873 1883 1888 1889 1896 1903\n",
      " 1909 1910 1919 1923 1933 1935 1939 1950 1956 1960 1961 1962 1964 1966\n",
      " 1968 1969 1976 1978 1984 1990 1993 1995 1997 1999 2001 2015 2019 2021\n",
      " 2023 2029 2030 2034 2042 2047 2050 2052 2053 2058 2064 2068 2078 2081\n",
      " 2085 2087 2091 2100 2102 2104 2120 2123 2131 2136 2142 2150 2154 2155\n",
      " 2157 2158 2163 2168 2176 2177 2178 2180 2182 2190 2191 2197 2200 2203\n",
      " 2217 2220 2221 2225 2227 2233 2242 2243 2246 2248 2255 2258 2268 2278\n",
      " 2281 2285 2288 2291 2313 2314 2331 2335 2339 2342 2343 2351 2358 2360\n",
      " 2362 2364 2368 2372 2379 2387 2396 2397 2406 2408 2414 2415 2418 2420\n",
      " 2432 2448 2451 2462 2474 2476 2484 2486 2487 2488 2491 2496 2501 2506\n",
      " 2507 2515 2518 2523 2530 2532 2533 2543 2546 2551 2562 2579 2585 2592\n",
      " 2594 2604 2605 2606 2613 2628 2640 2643 2652 2653 2654 2662 2670 2671\n",
      " 2674 2675 2676 2679 2680 2689 2693 2695 2696 2697 2701 2705 2710 2742\n",
      " 2746 2747 2752 2759 2760 2762 2764 2774 2775 2781 2787 2788 2799 2815\n",
      " 2820 2822 2824 2826 2836 2840 2842 2846 2855 2859 2864 2867 2871 2872\n",
      " 2873 2877 2878 2886 2906 2907 2911 2914 2924 2929 2930 2933 2936 2940\n",
      " 2942 2943 2945 2948 2950 2956 2959 2965 2971 2973 2975 2979 2985 2986\n",
      " 2987 2994 2996 2998 3002 3005 3008 3012 3015 3018 3019 3023 3028 3033\n",
      " 3036 3045 3047 3049 3050 3052 3066 3067 3071 3072 3089 3091 3110 3112\n",
      " 3118 3127 3128 3129 3144 3151 3154 3165 3170 3182 3187 3195 3200 3201\n",
      " 3213 3219 3222 3231 3233 3234 3237 3238 3242 3246 3263 3270 3278 3279\n",
      " 3280 3286 3291 3296 3302 3327 3329 3330 3332 3335 3338 3340 3348 3351\n",
      " 3358 3361 3368 3373 3379 3382 3384 3388 3390 3394 3402 3408 3415 3429]\n",
      "[   3    6   17   20   28   31   34   37   38   41   42   44   51   55\n",
      "   59   64   67   78   79   88   94  100  114  115  120  121  127  133\n",
      "  135  139  149  155  156  159  160  162  169  175  182  183  198  199\n",
      "  203  204  210  211  221  222  228  235  240  252  257  264  270  283\n",
      "  284  297  298  300  302  315  318  322  326  337  339  342  347  348\n",
      "  358  360  364  365  366  370  389  392  397  400  403  404  407  408\n",
      "  414  418  419  426  427  429  432  436  440  453  457  463  468  476\n",
      "  489  491  493  498  504  505  520  525  527  533  536  540  544  546\n",
      "  551  564  569  571  574  575  578  580  586  588  597  599  600  609\n",
      "  610  617  632  635  639  644  645  647  648  651  654  667  669  670\n",
      "  672  677  680  685  689  692  696  705  706  708  709  716  717  720\n",
      "  746  748  751  759  771  774  775  781  783  785  787  796  805  807\n",
      "  809  818  823  824  830  835  843  844  848  854  856  860  866  895\n",
      "  907  908  914  920  928  931  934  948  963  966  972  980  983  984\n",
      "  988  992 1000 1002 1003 1004 1009 1010 1013 1016 1024 1026 1029 1033\n",
      " 1034 1037 1056 1061 1074 1075 1081 1083 1087 1089 1097 1099 1102 1106\n",
      " 1109 1120 1122 1130 1132 1138 1145 1148 1154 1155 1157 1158 1160 1168\n",
      " 1173 1175 1185 1191 1192 1193 1196 1203 1205 1210 1211 1218 1219 1223\n",
      " 1226 1229 1236 1237 1240 1242 1248 1250 1260 1264 1268 1275 1277 1280\n",
      " 1287 1289 1292 1295 1304 1307 1311 1315 1317 1325 1329 1346 1347 1349\n",
      " 1350 1353 1359 1367 1369 1376 1380 1390 1397 1398 1399 1400 1408 1411\n",
      " 1419 1432 1433 1434 1438 1444 1458 1461 1464 1471 1477 1478 1481 1482\n",
      " 1486 1489 1490 1493 1496 1499 1504 1506 1507 1508 1522 1528 1544 1546\n",
      " 1548 1550 1559 1565 1566 1575 1578 1584 1606 1610 1611 1614 1617 1618\n",
      " 1622 1628 1632 1635 1638 1645 1646 1647 1659 1663 1665 1670 1672 1675\n",
      " 1681 1683 1687 1701 1712 1714 1718 1720 1723 1726 1729 1732 1740 1747\n",
      " 1750 1751 1752 1759 1764 1768 1770 1775 1784 1787 1789 1813 1815 1817\n",
      " 1818 1820 1821 1822 1824 1826 1828 1837 1840 1845 1856 1859 1870 1876\n",
      " 1882 1887 1894 1897 1899 1908 1911 1918 1926 1929 1931 1955 1958 1965\n",
      " 1977 1979 1981 1985 1992 1996 2002 2010 2013 2016 2017 2020 2028 2037\n",
      " 2039 2046 2051 2055 2062 2066 2075 2077 2079 2088 2097 2103 2114 2119\n",
      " 2121 2128 2133 2145 2147 2149 2162 2175 2193 2196 2201 2205 2207 2209\n",
      " 2211 2214 2215 2218 2228 2237 2239 2241 2245 2252 2259 2262 2266 2276\n",
      " 2277 2290 2296 2300 2304 2306 2310 2316 2318 2326 2344 2346 2349 2350\n",
      " 2354 2366 2370 2371 2373 2383 2386 2393 2398 2404 2413 2417 2419 2422\n",
      " 2424 2425 2426 2438 2445 2449 2459 2468 2472 2490 2495 2498 2502 2520\n",
      " 2521 2524 2541 2559 2570 2571 2574 2575 2583 2584 2602 2608 2610 2612\n",
      " 2616 2619 2623 2629 2632 2633 2646 2647 2659 2660 2661 2677 2678 2683\n",
      " 2685 2686 2687 2690 2698 2700 2703 2706 2708 2709 2715 2716 2725 2726\n",
      " 2728 2729 2734 2736 2738 2740 2745 2751 2758 2765 2766 2773 2783 2790\n",
      " 2792 2795 2796 2805 2806 2811 2813 2818 2827 2829 2830 2831 2832 2833\n",
      " 2852 2857 2869 2875 2884 2891 2892 2894 2896 2912 2922 2925 2927 2934\n",
      " 2944 2946 2951 2952 2962 2969 2970 2988 2989 2993 2995 3001 3009 3010\n",
      " 3020 3029 3035 3048 3056 3059 3062 3070 3083 3084 3086 3093 3094 3095\n",
      " 3097 3103 3107 3124 3125 3134 3137 3146 3147 3159 3164 3172 3177 3180\n",
      " 3185 3186 3203 3210 3217 3224 3226 3228 3235 3240 3241 3243 3248 3249\n",
      " 3250 3252 3255 3257 3262 3267 3269 3281 3283 3289 3290 3298 3314 3315\n",
      " 3316 3318 3319 3322 3331 3336 3349 3350 3352 3359 3360 3362 3365 3375\n",
      " 3380 3381 3392 3397 3399 3403 3405 3406 3418 3420 3424 3426 3427 3428]\n",
      "[   1    7   10   15   19   23   27   29   32   39   40   43   49   52\n",
      "   56   63   65   82   87   90   91   93  104  105  109  118  125  126\n",
      "  132  146  147  151  152  154  158  176  186  187  192  193  194  196\n",
      "  207  213  217  219  220  226  231  232  250  256  260  268  269  273\n",
      "  275  293  307  309  324  325  333  335  343  377  380  381  382  391\n",
      "  393  405  406  409  411  413  435  439  447  451  454  455  458  460\n",
      "  464  471  475  488  490  496  499  506  509  510  511  515  518  523\n",
      "  524  531  532  543  548  557  566  567  570  579  582  590  591  598\n",
      "  603  605  607  612  613  614  618  621  623  630  637  638  642  653\n",
      "  660  687  701  707  724  725  731  735  736  738  739  740  743  758\n",
      "  765  767  769  770  776  777  779  802  808  812  815  816  817  821\n",
      "  832  841  851  852  859  873  875  880  884  887  894  900  901  904\n",
      "  910  913  915  921  923  929  933  936  937  941  943  952  954  957\n",
      "  960  968  975  978  979  991  995 1015 1018 1022 1023 1032 1035 1036\n",
      " 1041 1047 1048 1054 1060 1062 1067 1071 1073 1084 1086 1088 1094 1105\n",
      " 1108 1111 1114 1119 1128 1131 1134 1135 1136 1149 1164 1166 1172 1176\n",
      " 1186 1189 1195 1199 1201 1213 1261 1262 1269 1272 1279 1281 1286 1288\n",
      " 1293 1296 1298 1302 1309 1318 1323 1324 1334 1345 1348 1366 1372 1382\n",
      " 1383 1391 1395 1401 1409 1410 1413 1414 1415 1416 1417 1421 1423 1429\n",
      " 1435 1439 1441 1442 1443 1454 1460 1465 1467 1475 1484 1487 1494 1497\n",
      " 1498 1510 1512 1521 1524 1529 1532 1535 1540 1542 1547 1555 1556 1569\n",
      " 1572 1583 1586 1591 1594 1597 1600 1604 1605 1608 1620 1623 1627 1634\n",
      " 1644 1651 1652 1660 1671 1673 1674 1690 1692 1698 1699 1702 1711 1716\n",
      " 1717 1719 1721 1724 1737 1742 1746 1754 1758 1761 1773 1776 1777 1783\n",
      " 1792 1798 1800 1806 1814 1819 1827 1829 1830 1831 1833 1834 1835 1842\n",
      " 1844 1851 1855 1857 1858 1866 1867 1869 1880 1881 1884 1890 1901 1904\n",
      " 1906 1913 1915 1917 1920 1922 1927 1930 1932 1945 1947 1954 1959 1974\n",
      " 1980 1983 1986 1988 2000 2003 2009 2012 2018 2024 2032 2036 2038 2044\n",
      " 2045 2048 2049 2060 2063 2069 2074 2076 2083 2089 2090 2096 2101 2111\n",
      " 2112 2113 2122 2125 2126 2135 2137 2143 2146 2152 2156 2165 2171 2174\n",
      " 2184 2186 2187 2189 2192 2195 2212 2213 2216 2223 2224 2230 2232 2235\n",
      " 2251 2256 2257 2261 2263 2265 2269 2279 2282 2284 2287 2292 2293 2295\n",
      " 2297 2299 2302 2303 2315 2319 2323 2328 2332 2337 2340 2341 2348 2359\n",
      " 2367 2375 2376 2389 2391 2392 2395 2399 2400 2401 2410 2412 2421 2423\n",
      " 2429 2430 2433 2436 2441 2442 2443 2447 2454 2456 2461 2465 2467 2470\n",
      " 2480 2481 2489 2500 2503 2505 2508 2509 2516 2519 2528 2529 2535 2536\n",
      " 2539 2542 2549 2553 2560 2561 2563 2567 2569 2572 2581 2586 2588 2589\n",
      " 2590 2601 2607 2611 2620 2624 2626 2627 2635 2638 2639 2642 2644 2649\n",
      " 2655 2657 2658 2663 2666 2668 2669 2672 2681 2694 2702 2711 2712 2724\n",
      " 2730 2735 2741 2748 2749 2761 2769 2771 2772 2777 2784 2789 2794 2800\n",
      " 2803 2810 2816 2817 2819 2844 2854 2858 2861 2868 2870 2876 2881 2887\n",
      " 2888 2895 2900 2903 2904 2905 2909 2913 2917 2918 2923 2926 2931 2937\n",
      " 2938 2941 2953 2958 2960 2967 2968 2972 2991 2997 2999 3003 3006 3007\n",
      " 3011 3021 3022 3025 3031 3032 3037 3038 3042 3044 3051 3055 3075 3080\n",
      " 3081 3085 3102 3105 3109 3113 3116 3117 3126 3130 3136 3148 3152 3156\n",
      " 3158 3161 3163 3168 3173 3174 3178 3179 3183 3191 3204 3205 3206 3208\n",
      " 3211 3212 3215 3216 3223 3227 3230 3232 3244 3253 3256 3258 3261 3264\n",
      " 3265 3266 3268 3271 3273 3276 3282 3292 3293 3297 3303 3308 3312 3317\n",
      " 3341 3346 3353 3354 3356 3363 3366 3383 3389 3391 3409 3416 3425 3430]\n",
      "[   2    8    9   11   14   22   25   35   45   46   47   60   62   69\n",
      "   72   75   81   97   98   99  107  110  117  134  137  141  143  145\n",
      "  148  150  153  164  165  166  167  170  172  178  189  190  214  223\n",
      "  224  227  236  238  242  243  245  247  248  249  251  253  261  276\n",
      "  277  278  279  280  287  291  301  303  310  313  316  317  319  327\n",
      "  328  329  330  331  334  341  345  349  351  352  354  356  362  373\n",
      "  375  378  384  386  390  395  396  398  416  417  430  434  437  442\n",
      "  443  444  446  449  456  461  467  473  474  480  483  485  486  507\n",
      "  508  516  521  522  528  538  541  559  561  583  587  608  622  625\n",
      "  627  631  640  646  657  658  659  661  676  681  686  691  698  699\n",
      "  702  703  711  719  722  726  727  729  733  742  744  745  755  756\n",
      "  762  768  786  793  795  798  799  801  804  811  822  827  829  833\n",
      "  839  846  853  855  862  865  868  879  882  888  893  897  899  903\n",
      "  905  916  919  930  942  947  955  958  959  965  969  976  977  981\n",
      "  990 1007 1011 1019 1020 1025 1027 1038 1043 1044 1046 1051 1052 1053\n",
      " 1070 1072 1077 1079 1082 1092 1096 1098 1101 1104 1113 1116 1133 1141\n",
      " 1142 1143 1147 1163 1165 1167 1170 1177 1180 1181 1198 1200 1202 1215\n",
      " 1216 1232 1233 1243 1247 1252 1256 1257 1259 1266 1274 1282 1290 1291\n",
      " 1294 1299 1300 1308 1313 1316 1320 1326 1330 1333 1339 1341 1342 1343\n",
      " 1352 1354 1356 1362 1364 1370 1375 1377 1389 1392 1403 1406 1407 1418\n",
      " 1422 1424 1428 1431 1436 1445 1446 1448 1451 1456 1462 1472 1476 1480\n",
      " 1492 1500 1502 1503 1505 1511 1514 1531 1536 1551 1553 1560 1563 1567\n",
      " 1570 1576 1577 1582 1607 1612 1613 1619 1625 1626 1629 1630 1641 1643\n",
      " 1650 1656 1657 1661 1662 1664 1678 1679 1682 1684 1686 1691 1694 1705\n",
      " 1706 1710 1715 1725 1727 1735 1739 1741 1748 1755 1763 1765 1767 1771\n",
      " 1772 1774 1788 1791 1801 1803 1825 1832 1839 1843 1849 1853 1861 1864\n",
      " 1874 1877 1893 1898 1907 1914 1916 1921 1924 1925 1928 1934 1937 1941\n",
      " 1942 1943 1949 1951 1953 1970 1971 1972 1973 1975 1987 1991 1998 2004\n",
      " 2008 2011 2025 2027 2031 2040 2056 2059 2061 2071 2072 2073 2082 2084\n",
      " 2086 2092 2095 2098 2108 2109 2115 2117 2118 2127 2129 2130 2132 2134\n",
      " 2138 2139 2144 2148 2151 2153 2159 2160 2166 2172 2183 2194 2204 2206\n",
      " 2210 2219 2226 2231 2240 2249 2250 2253 2254 2260 2270 2271 2272 2273\n",
      " 2274 2280 2283 2289 2307 2309 2311 2320 2321 2324 2325 2329 2330 2333\n",
      " 2336 2345 2347 2353 2365 2378 2388 2402 2403 2411 2416 2427 2434 2437\n",
      " 2439 2450 2453 2464 2466 2478 2482 2483 2492 2510 2512 2517 2525 2526\n",
      " 2527 2531 2538 2548 2550 2555 2556 2557 2564 2576 2582 2587 2597 2598\n",
      " 2603 2614 2622 2625 2630 2631 2634 2648 2665 2667 2682 2684 2691 2699\n",
      " 2707 2713 2717 2718 2721 2722 2727 2731 2732 2737 2739 2744 2750 2753\n",
      " 2754 2763 2768 2776 2778 2779 2780 2786 2793 2802 2804 2807 2808 2809\n",
      " 2812 2814 2821 2825 2828 2834 2835 2837 2839 2841 2843 2849 2850 2853\n",
      " 2856 2860 2865 2866 2882 2885 2893 2897 2898 2899 2901 2902 2915 2916\n",
      " 2919 2921 2928 2932 2935 2947 2954 2957 2961 2963 2966 2976 2977 2978\n",
      " 2980 3000 3017 3024 3026 3034 3039 3040 3043 3057 3058 3060 3061 3065\n",
      " 3068 3069 3074 3077 3078 3079 3082 3090 3092 3096 3100 3104 3106 3111\n",
      " 3115 3119 3121 3131 3132 3135 3138 3139 3142 3145 3149 3150 3153 3155\n",
      " 3160 3166 3167 3176 3181 3189 3190 3193 3202 3207 3218 3221 3225 3229\n",
      " 3239 3247 3251 3259 3260 3272 3275 3288 3294 3295 3300 3305 3306 3307\n",
      " 3310 3321 3325 3326 3328 3334 3339 3344 3345 3347 3355 3364 3370 3371\n",
      " 3372 3374 3376 3377 3386 3395 3400 3401 3404 3407 3411 3412 3413 3422]\n"
     ]
    }
   ],
   "source": [
    "for fold, (trn_ind, val_ind) in enumerate(kfold.split(X_train, y_train1)):\n",
    "    print(val_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, (trn_ind, val_ind) in enumerate(kfold.split(X_train, y_train1)):\n",
    "    print(' ')\n",
    "    print('-'*50)\n",
    "    print(f'Training fold {fold} with {len(features)} features...')\n",
    "    x_train, x_val = X_train[features].iloc[trn_ind], X_train[features].iloc[val_ind]\n",
    "    y_train, y_val = y_train1.iloc[trn_ind], y_train1.iloc[val_ind]\n",
    "    lgb_train = lgb.Dataset(x_train, y_train, categorical_feature = cat_features)\n",
    "    lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature = cat_features)\n",
    "    model = lgb.train(\n",
    "        params = params,\n",
    "        train_set = lgb_train,\n",
    "        num_boost_round = 10500,\n",
    "        valid_sets = [lgb_train, lgb_valid],\n",
    "        early_stopping_rounds = 1500,\n",
    "        verbose_eval = 500,\n",
    "        feval = lgb_amex_metric\n",
    "        )\n",
    "    # Save best model\n",
    "    pickle.dump(model, f'/home/slawa/code/code-rep0/projects/AMEX_default_prediction/pickles/lgbm_{CFG.boosting_type}_fold{fold}_seed{CFG.seed}.pkl')\n",
    "        # Predict validation\n",
    "    val_pred = model.predict(x_val)\n",
    "    # Add to out of folds array\n",
    "    oof_predictions[val_ind] = val_pred\n",
    "    # Predict the test set\n",
    "    test_pred = model.predict(test[features])\n",
    "    test_predictions += test_pred / CFG.n_folds # that is how it gets more or less a probability\n",
    "    # Compute fold metric\n",
    "    score = amex_metric(y_val, val_pred)\n",
    "    print(f'Our fold {fold} CV score is {score}')\n",
    "    del x_train, x_val, y_train, y_val, lgb_train, lgb_valid\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb = initialize_model(build_param_dict(categorical_features=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(bagging_fraction=1.0, categorical_feature=None,\n",
       "               feature_fraction=1.0, min_data_in_leaf=20, objective=&#x27;binary&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=1.0, categorical_feature=None,\n",
       "               feature_fraction=1.0, min_data_in_leaf=20, objective=&#x27;binary&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(bagging_fraction=1.0, categorical_feature=None,\n",
       "               feature_fraction=1.0, min_data_in_leaf=20, objective='binary')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lgb.fit(X_train, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_lgb.predict_proba(X_val)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67306840893694"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amex_metric(y_val1, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_imputer = SimpleImputer(strategy=\"most_frequent\") ## replace with KNNimputer on one neighbour, after transforming to numericals\n",
    "# #cat_imputer = KNNImputer(n_neighbors=1) # introducing it did not improve performance, but is computationally demanding\n",
    "# cat_encoder = OrdinalEncoder()\n",
    "# #cat_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore') ## what happens to the old columns?\n",
    "# cat_pipe = make_pipeline(cat_imputer, cat_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessor= ColumnTransformer([\n",
    "#         ('cat_pip', cat_pipe, cat_features)],\n",
    "#         remainder='passthrough' ## all columns not in num_vars and red_cat_vars are dropped.\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_pp = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(bagging_fraction=1.0, categorical_feature=None,\n",
       "               feature_fraction=1.0, min_data_in_leaf=20, objective=&#x27;binary&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=1.0, categorical_feature=None,\n",
       "               feature_fraction=1.0, min_data_in_leaf=20, objective=&#x27;binary&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(bagging_fraction=1.0, categorical_feature=None,\n",
       "               feature_fraction=1.0, min_data_in_leaf=20, objective='binary')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_lgb.predict_proba(X_val)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7123541944359542"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amex_metric(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7143069147981995"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amex_metric(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#         'objective': 'binary',\n",
    "#         'metric': CFG.metric,\n",
    "#         'boosting': CFG.boosting_type,\n",
    "#         'seed': CFG.seed,\n",
    "#         'num_leaves': 100,\n",
    "#         'learning_rate': 0.01,\n",
    "#         'feature_fraction': 0.20,\n",
    "#         'bagging_freq': 10,\n",
    "#         'bagging_fraction': 0.50,\n",
    "#         'n_jobs': -1,\n",
    "#         'lambda_l2': 2,\n",
    "#         'min_data_in_leaf': 40,\n",
    "#         }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('amex_default_pred')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a0841e2a88ce7e97cfea5e26b7ebbfeeacb2578913616b01dc1c1514acc11a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
